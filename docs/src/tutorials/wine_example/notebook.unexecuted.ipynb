{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Wine Quality Prediction: Comparing Categorical Encoders\n",
    "\n",
    "This tutorial compares different categorical encoding approaches on wine quality prediction.\n",
    "We'll test OneHot, Frequency, and Cardinality Reduction encoders with CatBoost regression.\n",
    "\n",
    "**Why compare encoders?** Categorical variables with many levels (like wine varieties)\n",
    "can create high-dimensional sparse features. Different encoding strategies handle this\n",
    "challenge differently, affecting both model performance and training speed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: we do not endorse drinking alcohol, this tutorial is purely for educational purposes."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg;\n",
    "Pkg.activate(@__DIR__);\n",
    "\n",
    "using MLJ, MLJTransforms, DataFrames, ScientificTypes\n",
    "using Random, CSV, StatsBase, Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load and Prepare Data\n",
    "Load the wine dataset and take a sample for faster computation.\n",
    "The dataset contains wine reviews with categorical features like variety, winery, and region:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = CSV.read(\"./clean_wine.csv\", DataFrame)\n",
    "\n",
    "first(df, 5)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sample 10,000 rows for faster computation (the full dataset is quite large):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = df[sample(1:nrow(df), 10000, replace = false), :];"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Coerce categorical columns to appropriate scientific types. We use `autotype` to automatically detect\n",
    "categorical features by recognizing columns with few unique values:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "df = coerce(df, autotype(df, :few_to_finite));\n",
    "df = coerce(df, :points => Continuous, :region_1 => Multiclass,\n",
    "    :variety => Multiclass, :winery => Multiclass);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split Data\n",
    "Separate features (X) from target (y), then split into train/test sets:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(df, ==(:points); rng = 123);\n",
    "train, test = partition(eachindex(y), 0.8, shuffle = true, rng = 100);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup Encoders and Model\n",
    "Load the required models and create different encoding strategies:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "OneHot = @load OneHotEncoder pkg = MLJModels verbosity = 0\n",
    "CatBoostRegressor = @load CatBoostRegressor pkg = CatBoost"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Encoding Strategies:**\n",
    "1. **OneHotEncoder**: Creates binary columns for each category\n",
    "2. **FrequencyEncoder**: Replaces categories with their frequency counts\n",
    "In case of the one-hot-encoder, we worry when categories have high cardinality as that would lead to an explosion in the number of features."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "card_reducer = MLJTransforms.CardinalityReducer(min_frequency = 10, ordered_factor = true)\n",
    "onehot_model = OneHot(drop_last = true, ordered_factor = true)\n",
    "freq_model = MLJTransforms.FrequencyEncoder(normalize = false, ordered_factor = true)\n",
    "cat = CatBoostRegressor();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create three different pipelines to compare:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipelines = [\n",
    "    (\"CardRed + OneHot + CAT\", card_reducer |> onehot_model |> cat),\n",
    "    (\"OneHot + CAT\", onehot_model |> cat),\n",
    "    (\"FreqEnc + CAT\", freq_model |> cat),\n",
    "]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate Pipelines\n",
    "Train each pipeline and measure both performance (RMSE) and training time:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "results = DataFrame(pipeline = String[], rmse = Float64[], training_time = Float64[]);\n",
    "\n",
    "for (name, pipe) in pipelines\n",
    "    println(\"Training: $name\")\n",
    "    mach = machine(pipe, X, y)\n",
    "    training_time = @elapsed MLJ.fit!(mach, rows = train)\n",
    "    predictions = MLJ.predict(mach, rows = test)\n",
    "    rmse_value = MLJ.root_mean_squared_error(y[test], predictions)\n",
    "    push!(results, (name, rmse_value, training_time))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Sort by RMSE (lower is better) and display results:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "sort!(results, :rmse)\n",
    "results"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization\n",
    "Create side-by-side bar charts to compare both training time and model performance:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "n = nrow(results)\n",
    "\n",
    "time_plot = bar(1:n, results.training_time;\n",
    "    xticks = (1:n, results.pipeline), title = \"Training Time (seconds)\",\n",
    "    xlabel = \"Pipeline\", ylabel = \"Time (s)\", xrotation = 45,\n",
    "    legend = false, color = :lightblue);\n",
    "\n",
    "rmse_plot = bar(1:n, results.rmse;\n",
    "    xticks = (1:n, results.pipeline), title = \"Root Mean Squared Error\",\n",
    "    xlabel = \"Pipeline\", ylabel = \"RMSE\", xrotation = 45,\n",
    "    legend = false, color = :lightcoral);\n",
    "\n",
    "combined_plot = plot(time_plot, rmse_plot; layout = (1, 2), size = (1200, 500));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the plot"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "savefig(combined_plot, \"wine_encoding_comparison.png\"); #hide"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "**Key Findings:**\n",
    "- The model performance did not vary significantly across encoding strategies.\n",
    "- We observe a decent speed up in using the cardinality reducer before one-hot encoding with close to no impact on performance.\n",
    "- That said, frequency encoder led to the least training time as it didn't add any new features"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
