<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>All Transformers · MLJTransforms</title><meta name="title" content="All Transformers · MLJTransforms"/><meta property="og:title" content="All Transformers · MLJTransforms"/><meta property="twitter:title" content="All Transformers · MLJTransforms"/><meta name="description" content="Documentation for MLJTransforms."/><meta property="og:description" content="Documentation for MLJTransforms."/><meta property="twitter:description" content="Documentation for MLJTransforms."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.gif" alt="MLJTransforms logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MLJTransforms</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Introduction</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox" checked/><label class="tocitem" for="menuitem-2"><span class="docs-label">Transformers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>All Transformers</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Encoders</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../classical/">Classical Encoders</a></li><li><a class="tocitem" href="../neural/">Neural-based Encoders</a></li><li><a class="tocitem" href="../contrast/">Contrast Encoders</a></li><li><a class="tocitem" href="../utility/">Utility Encoders</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Extended Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/standardization/notebook/">Standardization Impact</a></li><li><a class="tocitem" href="../../tutorials/classic_comparison/notebook/">Milk Quality Classification</a></li><li><a class="tocitem" href="../../tutorials/wine_example/notebook/">Wine Quality Prediction</a></li><li><a class="tocitem" href="../../tutorials/entity_embeddings/notebook/">Entity Embeddings Tutorial</a></li></ul></li><li><a class="tocitem" href="../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../about/">About</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Transformers</a></li><li class="is-active"><a href>All Transformers</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>All Transformers</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJTransforms.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/dev/docs/src/transformers/all_transformers.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h3 id="Summary-Table"><a class="docs-heading-anchor" href="#Summary-Table">Summary Table</a><a id="Summary-Table-1"></a><a class="docs-heading-anchor-permalink" href="#Summary-Table" title="Permalink"></a></h3><table><tr><th style="text-align: center">Transformer</th><th style="text-align: center">Brief Description</th></tr><tr><td style="text-align: center"><a href="../numerical/#MLJTransforms.Standardizer">Standardizer</a></td><td style="text-align: center">Transforming columns of numerical features by standardization</td></tr><tr><td style="text-align: center"><a href="@ref">UnivariateBoxCoxTransformer</a></td><td style="text-align: center">Apply BoxCox transformation given a single vector</td></tr><tr><td style="text-align: center"><a href="../numerical/#MLJTransforms.InteractionTransformer">InteractionTransformer</a></td><td style="text-align: center">Transforming columns of numerical features to create new interaction features</td></tr><tr><td style="text-align: center"><a href="../numerical/#MLJTransforms.UnivariateDiscretizer">UnivariateDiscretizer</a></td><td style="text-align: center">Discretize a continuous vector into an ordered factor</td></tr><tr><td style="text-align: center"><a href="../numerical/#MLJTransforms.FillImputer">FillImputer</a></td><td style="text-align: center">Fill missing values of features belonging to any scientific type</td></tr><tr><td style="text-align: center"><a href="../others/#MLJTransforms.UnivariateTimeTypeToContinuous">UnivariateTimeTypeToContinuous</a></td><td style="text-align: center">Transform a vector of time type into continuous type</td></tr><tr><td style="text-align: center"><a href="../classical/#MLJTransforms.OneHotEncoder">OneHotEncoder</a></td><td style="text-align: center">Encode categorical variables into one-hot vectors</td></tr><tr><td style="text-align: center"><a href="../classical/#MLJTransforms.ContinuousEncoder">ContinuousEncoder</a></td><td style="text-align: center">Adds type casting functionality to OnehotEncoder</td></tr><tr><td style="text-align: center"><a href="../classical/#MLJTransforms.OrdinalEncoder">OrdinalEncoder</a></td><td style="text-align: center">Encode categorical variables into ordered integers</td></tr><tr><td style="text-align: center"><a href="../classical/#MLJTransforms.FrequencyEncoder">FrequencyEncoder</a></td><td style="text-align: center">Encode categorical variables into their normalized or unormalized frequencies</td></tr><tr><td style="text-align: center"><a href="../classical/#MLJTransforms.TargetEncoder">TargetEncoder</a></td><td style="text-align: center">Encode categorical variables into relevant target statistics</td></tr><tr><td style="text-align: center"><a href="@ref">DummyEncoder</a></td><td style="text-align: center">Encodes by comparing each level to the reference level, intercept being the cell mean of the reference group</td></tr><tr><td style="text-align: center"><a href="@ref">SumEncoder</a></td><td style="text-align: center">Encodes by comparing each level to the reference level, intercept being the grand mean</td></tr><tr><td style="text-align: center"><a href="@ref">HelmertEncoder</a></td><td style="text-align: center">Encodes by comparing levels of a variable with the mean of the subsequent levels of the variable</td></tr><tr><td style="text-align: center"><a href="@ref">ForwardDifferenceEncoder</a></td><td style="text-align: center">Encodes by comparing adjacent levels of a variable (each level minus the next level)</td></tr><tr><td style="text-align: center"><a href="../contrast/#MLJTransforms.ContrastEncoder">ContrastEncoder</a></td><td style="text-align: center">Allows defining a custom contrast encoder via a contrast matrix</td></tr><tr><td style="text-align: center"><a href="@ref">HypothesisEncoder</a></td><td style="text-align: center">Allows defining a custom contrast encoder via a hypothesis matrix</td></tr><tr><td style="text-align: center"><a href="@ref">EntityEmbedders</a></td><td style="text-align: center">Encode categorical variables into dense embedding vectors</td></tr><tr><td style="text-align: center"><a href="../utility/#MLJTransforms.CardinalityReducer">CardinalityReducer</a></td><td style="text-align: center">Reduce cardinality of high cardinality categorical features by grouping infrequent categories</td></tr><tr><td style="text-align: center"><a href="../utility/#MLJTransforms.MissingnessEncoder">MissingnessEncoder</a></td><td style="text-align: center">Encode missing values of categorical features into new values</td></tr></table><h3 id="All-Transformers"><a class="docs-heading-anchor" href="#All-Transformers">All Transformers</a><a id="All-Transformers-1"></a><a class="docs-heading-anchor-permalink" href="#All-Transformers" title="Permalink"></a></h3><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.Standardizer-transformers-all_transformers" href="#MLJTransforms.Standardizer-transformers-all_transformers"><code>MLJTransforms.Standardizer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">Standardizer</code></pre><p>A model type for constructing a standardizer, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">Standardizer = @load Standardizer pkg=unknown</code></pre><p>Do <code>model = Standardizer()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>Standardizer(features=...)</code>.</p><p>Use this model to standardize (whiten) a <code>Continuous</code> vector, or relevant columns of a table. The rescalings applied by this transformer to new data are always those learned during the training phase, which are generally different from what would actually standardize the new data.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>where</p><ul><li><code>X</code>: any Tables.jl compatible table or any abstract vector with <code>Continuous</code> element scitype (any abstract float vector). Only features in a table with <code>Continuous</code> scitype can be standardized; check column scitypes with <code>schema(X)</code>.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features</code>: one of the following, with the behavior indicated below:</p><ul><li><p><code>[]</code> (empty, the default): standardize all features (columns) having <code>Continuous</code> element scitype</p></li><li><p>non-empty vector of feature names (symbols): standardize only the <code>Continuous</code> features in the vector (if <code>ignore=false</code>) or <code>Continuous</code> features <em>not</em> named in the vector (<code>ignore=true</code>).</p></li><li><p>function or other callable: standardize a feature if the callable returns <code>true</code> on its name. For example, <code>Standardizer(features = name -&gt; name in [:x1, :x3], ignore = true, count=true)</code> has the same effect as <code>Standardizer(features = [:x1, :x3], ignore = true, count=true)</code>, namely to standardize all <code>Continuous</code> and <code>Count</code> features, with the exception of <code>:x1</code> and <code>:x3</code>.</p></li></ul><p>Note this behavior is further modified if the <code>ordered_factor</code> or <code>count</code> flags are set to <code>true</code>; see below</p></li><li><p><code>ignore=false</code>: whether to ignore or standardize specified <code>features</code>, as explained above</p></li><li><p><code>ordered_factor=false</code>: if <code>true</code>, standardize any <code>OrderedFactor</code> feature wherever a <code>Continuous</code> feature would be standardized, as described above</p></li><li><p><code>count=false</code>: if <code>true</code>, standardize any <code>Count</code> feature wherever a <code>Continuous</code> feature would be standardized, as described above</p></li></ul><p><strong>Operations</strong></p><ul><li><p><code>transform(mach, Xnew)</code>: return <code>Xnew</code> with relevant features standardized according to the rescalings learned during fitting of <code>mach</code>.</p></li><li><p><code>inverse_transform(mach, Z)</code>: apply the inverse transformation to <code>Z</code>, so that <code>inverse_transform(mach, transform(mach, Xnew))</code> is approximately the same as <code>Xnew</code>; unavailable if <code>ordered_factor</code> or <code>count</code> flags were set to <code>true</code>.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>features_fit</code> - the names of features that will be standardized</p></li><li><p><code>means</code> - the corresponding untransformed mean values</p></li><li><p><code>stds</code> - the corresponding untransformed standard deviations</p></li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>features_fit</code>: the names of features that will be standardized</li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using MLJ

X = (ordinal1 = [1, 2, 3],
     ordinal2 = coerce([:x, :y, :x], OrderedFactor),
     ordinal3 = [10.0, 20.0, 30.0],
     ordinal4 = [-20.0, -30.0, -40.0],
     nominal = coerce([&quot;Your father&quot;, &quot;he&quot;, &quot;is&quot;], Multiclass));

julia&gt; schema(X)
┌──────────┬──────────────────┐
│ names    │ scitypes         │
├──────────┼──────────────────┤
│ ordinal1 │ Count            │
│ ordinal2 │ OrderedFactor{2} │
│ ordinal3 │ Continuous       │
│ ordinal4 │ Continuous       │
│ nominal  │ Multiclass{3}    │
└──────────┴──────────────────┘

stand1 = Standardizer();

julia&gt; transform(fit!(machine(stand1, X)), X)
(ordinal1 = [1, 2, 3],
 ordinal2 = CategoricalValue{Symbol,UInt32}[:x, :y, :x],
 ordinal3 = [-1.0, 0.0, 1.0],
 ordinal4 = [1.0, 0.0, -1.0],
 nominal = CategoricalValue{String,UInt32}[&quot;Your father&quot;, &quot;he&quot;, &quot;is&quot;],)

stand2 = Standardizer(features=[:ordinal3, ], ignore=true, count=true);

julia&gt; transform(fit!(machine(stand2, X)), X)
(ordinal1 = [-1.0, 0.0, 1.0],
 ordinal2 = CategoricalValue{Symbol,UInt32}[:x, :y, :x],
 ordinal3 = [10.0, 20.0, 30.0],
 ordinal4 = [1.0, 0.0, -1.0],
 nominal = CategoricalValue{String,UInt32}[&quot;Your father&quot;, &quot;he&quot;, &quot;is&quot;],)</code></pre><p>See also <a href="../classical/#MLJTransforms.OneHotEncoder"><code>OneHotEncoder</code></a>, <a href="../classical/#MLJTransforms.ContinuousEncoder"><code>ContinuousEncoder</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/standardizer.jl#L239-L254">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.InteractionTransformer-transformers-all_transformers" href="#MLJTransforms.InteractionTransformer-transformers-all_transformers"><code>MLJTransforms.InteractionTransformer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">InteractionTransformer</code></pre><p>A model type for constructing a interaction transformer, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">InteractionTransformer = @load InteractionTransformer pkg=unknown</code></pre><p>Do <code>model = InteractionTransformer()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>InteractionTransformer(order=...)</code>.</p><p>Generates all polynomial interaction terms up to the given order for the subset of chosen columns.  Any column that contains elements with scitype <code>&lt;:Infinite</code> is a valid basis to generate interactions.  If <code>features</code> is not specified, all such columns with scitype <code>&lt;:Infinite</code> in the table are used as a basis.</p><p>In MLJ or MLJBase, you can transform features <code>X</code> with the single call</p><pre><code class="nohighlight hljs">transform(machine(model), X)</code></pre><p>See also the example below.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>order</code>: Maximum order of interactions to be generated.</li><li><code>features</code>: Restricts interations generation to those columns</li></ul><p><strong>Operations</strong></p><ul><li><code>transform(machine(model), X)</code>: Generates polynomial interaction terms out of table <code>X</code> using the hyper-parameters specified in <code>model</code>.</li></ul><p><strong>Example</strong></p><pre><code class="nohighlight hljs">using MLJ

X = (
    A = [1, 2, 3],
    B = [4, 5, 6],
    C = [7, 8, 9],
    D = [&quot;x₁&quot;, &quot;x₂&quot;, &quot;x₃&quot;]
)
it = InteractionTransformer(order=3)
mach = machine(it)

julia&gt; transform(mach, X)
(A = [1, 2, 3],
 B = [4, 5, 6],
 C = [7, 8, 9],
 D = [&quot;x₁&quot;, &quot;x₂&quot;, &quot;x₃&quot;],
 A_B = [4, 10, 18],
 A_C = [7, 16, 27],
 B_C = [28, 40, 54],
 A_B_C = [28, 80, 162],)

it = InteractionTransformer(order=2, features=[:A, :B])
mach = machine(it)

julia&gt; transform(mach, X)
(A = [1, 2, 3],
 B = [4, 5, 6],
 C = [7, 8, 9],
 D = [&quot;x₁&quot;, &quot;x₂&quot;, &quot;x₃&quot;],
 A_B = [4, 10, 18],)
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/interaction_transformer.jl#L43-L58">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.UnivariateDiscretizer-transformers-all_transformers" href="#MLJTransforms.UnivariateDiscretizer-transformers-all_transformers"><code>MLJTransforms.UnivariateDiscretizer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UnivariateDiscretizer</code></pre><p>A model type for constructing a single variable discretizer, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">UnivariateDiscretizer = @load UnivariateDiscretizer pkg=unknown</code></pre><p>Do <code>model = UnivariateDiscretizer()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>UnivariateDiscretizer(n_classes=...)</code>.</p><p>Discretization converts a <code>Continuous</code> vector into an <code>OrderedFactor</code> vector. In particular, the output is a <code>CategoricalVector</code> (whose reference type is optimized).</p><p>The transformation is chosen so that the vector on which the transformer is fit has, in transformed form, an approximately uniform distribution of values. Specifically, if <code>n_classes</code> is the level of discretization, then <code>2*n_classes - 1</code> ordered quantiles are computed, the odd quantiles being used for transforming (discretization) and the even quantiles for inverse transforming.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, x)</code></pre><p>where</p><ul><li><code>x</code>: any abstract vector with <code>Continuous</code> element scitype; check scitype with <code>scitype(x)</code>.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><code>n_classes</code>: number of discrete classes in the output</li></ul><p><strong>Operations</strong></p><ul><li><p><code>transform(mach, xnew)</code>: discretize <code>xnew</code> according to the discretization learned when fitting <code>mach</code></p></li><li><p><code>inverse_transform(mach, z)</code>: attempt to reconstruct from <code>z</code> a vector that transforms to give <code>z</code></p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach).fitesult</code> include:</p><ul><li><p><code>odd_quantiles</code>: quantiles used for transforming (length is <code>n_classes - 1</code>)</p></li><li><p><code>even_quantiles</code>: quantiles used for inverse transforming (length is <code>n_classes</code>)</p></li></ul><p><strong>Example</strong></p><pre><code class="nohighlight hljs">using MLJ
using Random
Random.seed!(123)

discretizer = UnivariateDiscretizer(n_classes=100)
mach = machine(discretizer, randn(1000))
fit!(mach)

julia&gt; x = rand(5)
5-element Vector{Float64}:
 0.8585244609846809
 0.37541692370451396
 0.6767070590395461
 0.9208844241267105
 0.7064611415680901

julia&gt; z = transform(mach, x)
5-element CategoricalArrays.CategoricalArray{UInt8,1,UInt8}:
 0x52
 0x42
 0x4d
 0x54
 0x4e

x_approx = inverse_transform(mach, z)
julia&gt; x - x_approx
5-element Vector{Float64}:
 0.008224506144777322
 0.012731354778359405
 0.0056265330571125816
 0.005738175684445124
 0.006835652575801987</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/univariate_discretizer.jl#L100-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.FillImputer-transformers-all_transformers" href="#MLJTransforms.FillImputer-transformers-all_transformers"><code>MLJTransforms.FillImputer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">FillImputer</code></pre><p>A model type for constructing a fill imputer, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">FillImputer = @load FillImputer pkg=unknown</code></pre><p>Do <code>model = FillImputer()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>FillImputer(features=...)</code>.</p><p>Use this model to impute <code>missing</code> values in tabular data. A fixed &quot;filler&quot; value is learned from the training data, one for each column of the table.</p><p>For imputing missing values in a vector, use <a href="@ref"><code>UnivariateFillImputer</code></a> instead.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>where</p><ul><li><code>X</code>: any table of input features (eg, a <code>DataFrame</code>) whose features each have element scitypes <code>Union{Missing, T}</code>, where <code>T</code> is a subtype of <code>Continuous</code>, <code>Multiclass</code>, <code>OrderedFactor</code> or <code>Count</code>. Check scitypes with <code>schema(X)</code>.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features</code>: a vector of names of features (symbols) for which imputation is to be attempted; default is empty, which is interpreted as &quot;impute all&quot;.</p></li><li><p><code>continuous_fill</code>: function or other callable to determine value to be imputed in the case of <code>Continuous</code> (abstract float) data; default is to apply <code>median</code> after skipping <code>missing</code> values</p></li><li><p><code>count_fill</code>: function or other callable to determine value to be imputed in the case of <code>Count</code> (integer) data; default is to apply rounded <code>median</code> after skipping <code>missing</code> values</p></li><li><p><code>finite_fill</code>: function or other callable to determine value to be imputed in the case of <code>Multiclass</code> or <code>OrderedFactor</code> data (categorical vectors); default is to apply <code>mode</code> after skipping <code>missing</code> values</p></li></ul><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: return <code>Xnew</code> with missing values imputed with the fill values learned when fitting <code>mach</code></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>features_seen_in_fit</code>: the names of features (features) encountered during training</p></li><li><p><code>univariate_transformer</code>: the univariate model applied to determine   the fillers (it&#39;s fields contain the functions defining the filler computations)</p></li><li><p><code>filler_given_feature</code>: dictionary of filler values, keyed on feature (column) names</p></li></ul><p><strong>Examples</strong></p><pre><code class="nohighlight hljs">using MLJ
imputer = FillImputer()

X = (a = [1.0, 2.0, missing, 3.0, missing],
     b = coerce([&quot;y&quot;, &quot;n&quot;, &quot;y&quot;, missing, &quot;y&quot;], Multiclass),
     c = [1, 1, 2, missing, 3])

schema(X)
julia&gt; schema(X)
┌───────┬───────────────────────────────┐
│ names │ scitypes                      │
├───────┼───────────────────────────────┤
│ a     │ Union{Missing, Continuous}    │
│ b     │ Union{Missing, Multiclass{2}} │
│ c     │ Union{Missing, Count}         │
└───────┴───────────────────────────────┘

mach = machine(imputer, X)
fit!(mach)

julia&gt; fitted_params(mach).filler_given_feature
(filler = 2.0,)

julia&gt; fitted_params(mach).filler_given_feature
Dict{Symbol, Any} with 3 entries:
  :a =&gt; 2.0
  :b =&gt; &quot;y&quot;
  :c =&gt; 2

julia&gt; transform(mach, X)
(a = [1.0, 2.0, 2.0, 3.0, 2.0],
 b = CategoricalValue{String, UInt32}[&quot;y&quot;, &quot;n&quot;, &quot;y&quot;, &quot;y&quot;, &quot;y&quot;],
 c = [1, 1, 2, 2, 3],)</code></pre><p>See also <a href="@ref"><code>UnivariateFillImputer</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/fill_imputer.jl#L299-L314">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.UnivariateTimeTypeToContinuous-transformers-all_transformers" href="#MLJTransforms.UnivariateTimeTypeToContinuous-transformers-all_transformers"><code>MLJTransforms.UnivariateTimeTypeToContinuous</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">UnivariateTimeTypeToContinuous</code></pre><p>A model type for constructing a single variable transformer that creates continuous representations of temporally typed data, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">UnivariateTimeTypeToContinuous = @load UnivariateTimeTypeToContinuous pkg=unknown</code></pre><p>Do <code>model = UnivariateTimeTypeToContinuous()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>UnivariateTimeTypeToContinuous(zero_time=...)</code>.</p><p>Use this model to convert vectors with a <code>TimeType</code> element type to vectors of <code>Float64</code> type (<code>Continuous</code> element scitype).</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, x)</code></pre><p>where</p><ul><li><code>x</code>: any abstract vector whose element type is a subtype of <code>Dates.TimeType</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>zero_time</code>: the time that is to correspond to 0.0 under transformations, with the type coinciding with the training data element type. If unspecified, the earliest time encountered in training is used.</p></li><li><p><code>step::Period=Hour(24)</code>: time interval to correspond to one unit under transformation</p></li></ul><p><strong>Operations</strong></p><ul><li><code>transform(mach, xnew)</code>: apply the encoding inferred when <code>mach</code> was fit</li></ul><p><strong>Fitted parameters</strong></p><p><code>fitted_params(mach).fitresult</code> is the tuple <code>(zero_time, step)</code> actually used in transformations, which may differ from the user-specified hyper-parameters.</p><p><strong>Example</strong></p><pre><code class="nohighlight hljs">using MLJ
using Dates

x = [Date(2001, 1, 1) + Day(i) for i in 0:4]

encoder = UnivariateTimeTypeToContinuous(zero_time=Date(2000, 1, 1),
                                         step=Week(1))

mach = machine(encoder, x)
fit!(mach)
julia&gt; transform(mach, x)
5-element Vector{Float64}:
 52.285714285714285
 52.42857142857143
 52.57142857142857
 52.714285714285715
 52.857142</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/univariate_time_type_to_continuous.jl#L134-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.OneHotEncoder-transformers-all_transformers" href="#MLJTransforms.OneHotEncoder-transformers-all_transformers"><code>MLJTransforms.OneHotEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OneHotEncoder</code></pre><p>A model type for constructing a one-hot encoder, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">OneHotEncoder = @load OneHotEncoder pkg=unknown</code></pre><p>Do <code>model = OneHotEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>OneHotEncoder(features=...)</code>.</p><p>Use this model to one-hot encode the <code>Multiclass</code> and <code>OrderedFactor</code> features (columns) of some table, leaving other columns unchanged.</p><p>New data to be transformed may lack features present in the fit data, but no <em>new</em> features can be present.</p><p><strong>Warning:</strong> This transformer assumes that <code>levels(col)</code> for any <code>Multiclass</code> or <code>OrderedFactor</code> column, <code>col</code>, is the same for training data and new data to be transformed.</p><p>To ensure <em>all</em> features are transformed into <code>Continuous</code> features, or dropped, use <a href="../classical/#MLJTransforms.ContinuousEncoder"><code>ContinuousEncoder</code></a> instead.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>where</p><ul><li><code>X</code>: any Tables.jl compatible table. Columns can be of mixed type but only those with element scitype <code>Multiclass</code> or <code>OrderedFactor</code> can be encoded. Check column scitypes with <code>schema(X)</code>.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features</code>: a vector of symbols (feature names). If empty (default) then all <code>Multiclass</code> and <code>OrderedFactor</code> features are encoded. Otherwise, encoding is further restricted to the specified features (<code>ignore=false</code>) or the unspecified features (<code>ignore=true</code>). This default behavior can be modified by the <code>ordered_factor</code> flag.</p></li><li><p><code>ordered_factor=false</code>: when <code>true</code>, <code>OrderedFactor</code> features are universally excluded</p></li><li><p><code>drop_last=true</code>: whether to drop the column corresponding to the final class of encoded features. For example, a three-class feature is spawned into three new features if <code>drop_last=false</code>, but just two features otherwise.</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>all_features</code>: names of all features encountered in training</p></li><li><p><code>fitted_levels_given_feature</code>: dictionary of the levels associated with each feature encoded, keyed on the feature name</p></li><li><p><code>ref_name_pairs_given_feature</code>: dictionary of pairs <code>r =&gt; ftr</code> (such as <code>0x00000001 =&gt; :grad__A</code>) where <code>r</code> is a CategoricalArrays.jl reference integer representing a level, and <code>ftr</code> the corresponding new feature name; the dictionary is keyed on the names of features that are encoded</p></li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><p><code>features_to_be_encoded</code>: names of input features to be encoded</p></li><li><p><code>new_features</code>: names of all output features</p></li></ul><p><strong>Example</strong></p><pre><code class="nohighlight hljs">using MLJ

X = (name=categorical([&quot;Danesh&quot;, &quot;Lee&quot;, &quot;Mary&quot;, &quot;John&quot;]),
     grade=categorical([&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;], ordered=true),
     height=[1.85, 1.67, 1.5, 1.67],
     n_devices=[3, 2, 4, 3])

julia&gt; schema(X)
┌───────────┬──────────────────┐
│ names     │ scitypes         │
├───────────┼──────────────────┤
│ name      │ Multiclass{4}    │
│ grade     │ OrderedFactor{3} │
│ height    │ Continuous       │
│ n_devices │ Count            │
└───────────┴──────────────────┘

hot = OneHotEncoder(drop_last=true)
mach = fit!(machine(hot, X))
W = transform(mach, X)

julia&gt; schema(W)
┌──────────────┬────────────┐
│ names        │ scitypes   │
├──────────────┼────────────┤
│ name__Danesh │ Continuous │
│ name__John   │ Continuous │
│ name__Lee    │ Continuous │
│ grade__A     │ Continuous │
│ grade__B     │ Continuous │
│ height       │ Continuous │
│ n_devices    │ Count      │
└──────────────┴────────────┘</code></pre><p>See also <a href="../classical/#MLJTransforms.ContinuousEncoder"><code>ContinuousEncoder</code></a>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/one_hot_encoder.jl#L168-L183">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.ContinuousEncoder-transformers-all_transformers" href="#MLJTransforms.ContinuousEncoder-transformers-all_transformers"><code>MLJTransforms.ContinuousEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ContinuousEncoder</code></pre><p>A model type for constructing a continuous encoder, based on <a href="unknown">unknown.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">ContinuousEncoder = @load ContinuousEncoder pkg=unknown</code></pre><p>Do <code>model = ContinuousEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>ContinuousEncoder(drop_last=...)</code>.</p><p>Use this model to arrange all features (features) of a table to have <code>Continuous</code> element scitype, by applying the following protocol to each feature <code>ftr</code>:</p><ul><li><p>If <code>ftr</code> is already <code>Continuous</code> retain it.</p></li><li><p>If <code>ftr</code> is <code>Multiclass</code>, one-hot encode it.</p></li><li><p>If <code>ftr</code> is <code>OrderedFactor</code>, replace it with <code>coerce(ftr, Continuous)</code> (vector of floating point integers), unless <code>ordered_factors=false</code> is specified, in which case one-hot encode it.</p></li><li><p>If <code>ftr</code> is <code>Count</code>, replace it with <code>coerce(ftr, Continuous)</code>.</p></li><li><p>If <code>ftr</code> has some other element scitype, or was not observed in fitting the encoder, drop it from the table.</p></li></ul><p><strong>Warning:</strong> This transformer assumes that <code>levels(col)</code> for any <code>Multiclass</code> or <code>OrderedFactor</code> column, <code>col</code>, is the same for training data and new data to be transformed.</p><p>To selectively one-hot-encode categorical features (without dropping features) use <a href="../classical/#MLJTransforms.OneHotEncoder"><code>OneHotEncoder</code></a> instead.</p><p><strong>Training data</strong></p><p>In MLJ or MLJBase, bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>where</p><ul><li><code>X</code>: any Tables.jl compatible table. features can be of mixed type but only those with element scitype <code>Multiclass</code> or <code>OrderedFactor</code> can be encoded. Check column scitypes with <code>schema(X)</code>.</li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>drop_last=true</code>: whether to drop the column corresponding to the final class of one-hot encoded features. For example, a three-class feature is spawned into three new features if <code>drop_last=false</code>, but two just features otherwise.</p></li><li><p><code>one_hot_ordered_factors=false</code>: whether to one-hot any feature with <code>OrderedFactor</code> element scitype, or to instead coerce it directly to a (single) <code>Continuous</code> feature using the order</p></li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><p><code>features_to_keep</code>: names of features that will not be dropped from the table</p></li><li><p><code>one_hot_encoder</code>: the <code>OneHotEncoder</code> model instance for handling the one-hot encoding</p></li><li><p><code>one_hot_encoder_fitresult</code>: the fitted parameters of the <code>OneHotEncoder</code> model</p></li></ul><p><strong>Report</strong></p><ul><li><p><code>features_to_keep</code>: names of input features that will not be dropped from the table</p></li><li><p><code>new_features</code>: names of all output features</p></li></ul><p><strong>Example</strong></p><pre><code class="language-julia hljs">X = (name=categorical([&quot;Danesh&quot;, &quot;Lee&quot;, &quot;Mary&quot;, &quot;John&quot;]),
     grade=categorical([&quot;A&quot;, &quot;B&quot;, &quot;A&quot;, &quot;C&quot;], ordered=true),
     height=[1.85, 1.67, 1.5, 1.67],
     n_devices=[3, 2, 4, 3],
     comments=[&quot;the force&quot;, &quot;be&quot;, &quot;with you&quot;, &quot;too&quot;])

julia&gt; schema(X)
┌───────────┬──────────────────┐
│ names     │ scitypes         │
├───────────┼──────────────────┤
│ name      │ Multiclass{4}    │
│ grade     │ OrderedFactor{3} │
│ height    │ Continuous       │
│ n_devices │ Count            │
│ comments  │ Textual          │
└───────────┴──────────────────┘

encoder = ContinuousEncoder(drop_last=true)
mach = fit!(machine(encoder, X))
W = transform(mach, X)

julia&gt; schema(W)
┌──────────────┬────────────┐
│ names        │ scitypes   │
├──────────────┼────────────┤
│ name__Danesh │ Continuous │
│ name__John   │ Continuous │
│ name__Lee    │ Continuous │
│ grade        │ Continuous │
│ height       │ Continuous │
│ n_devices    │ Continuous │
└──────────────┴────────────┘

julia&gt; setdiff(schema(X).names, report(mach).features_to_keep) # dropped features
1-element Vector{Symbol}:
 :comments
</code></pre><p>See also <a href="../classical/#MLJTransforms.OneHotEncoder"><code>OneHotEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/other_transformers/continuous_encoder.jl#L78-L93">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.OrdinalEncoder-transformers-all_transformers" href="#MLJTransforms.OrdinalEncoder-transformers-all_transformers"><code>MLJTransforms.OrdinalEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">OrdinalEncoder</code></pre><p>A model type for constructing a ordinal encoder, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">OrdinalEncoder = @load OrdinalEncoder pkg=MLJTransforms</code></pre><p>Do <code>model = OrdinalEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>OrdinalEncoder(features=...)</code>.</p><p><code>OrdinalEncoder</code> implements ordinal encoding which replaces the categorical values in the specified     categorical features with integers (ordered arbitrarily). This will create an implicit ordering between     categories which may not be a proper modelling assumption.</p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance unsupervised <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li><li><p><code>output_type</code>: The numerical concrete type of the encoded features. Default is <code>Float32</code>.</p></li></ul><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply ordinal encoding to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table.   Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>index_given_feat_level</code>: A dictionary that maps each level for each column in a subset of the categorical features of X into an integer. </li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using MLJ

# Define categorical features
A = [&quot;g&quot;, &quot;b&quot;, &quot;g&quot;, &quot;r&quot;, &quot;r&quot;,]  
B = [1.0, 2.0, 3.0, 4.0, 5.0,]
C = [&quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;,]  
D = [true, false, true, false, true,]
E = [1, 2, 3, 4, 5,]

# Combine into a named tuple
X = (A = A, B = B, C = C, D = D, E = E)

# Coerce A, C, D to multiclass and B to continuous and E to ordinal
X = coerce(X,
:A =&gt; Multiclass,
:B =&gt; Continuous,
:C =&gt; Multiclass,
:D =&gt; Multiclass,
:E =&gt; OrderedFactor,
)

# Check scitype coercion:
schema(X)

encoder = OrdinalEncoder(ordered_factor = false)
mach = fit!(machine(encoder, X))
Xnew = transform(mach, X)

julia &gt; Xnew
    (A = [2, 1, 2, 3, 3],
    B = [1.0, 2.0, 3.0, 4.0, 5.0],
    C = [1, 1, 1, 2, 1],
    D = [2, 1, 2, 1, 2],
    E = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 2, 3, 4, 5],)</code></pre><p>See also <a href="../classical/#MLJTransforms.TargetEncoder"><code>TargetEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/encoders/ordinal_encoding/interface_mlj.jl#L70-L94">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.FrequencyEncoder-transformers-all_transformers" href="#MLJTransforms.FrequencyEncoder-transformers-all_transformers"><code>MLJTransforms.FrequencyEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">FrequencyEncoder</code></pre><p>A model type for constructing a frequency encoder, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">FrequencyEncoder = @load FrequencyEncoder pkg=MLJTransforms</code></pre><p>Do <code>model = FrequencyEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>FrequencyEncoder(features=...)</code>.</p><p><code>FrequencyEncoder</code> implements frequency encoding which replaces the categorical values in the specified     categorical features with their (normalized or raw) frequencies of occurrence in the dataset. </p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance unsupervised <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li><li><p><code>normalize=false</code>: Whether to use normalized frequencies that sum to 1 over category values or to use raw counts.</p></li><li><p><code>output_type=Float32</code>: The type of the output values. The default is <code>Float32</code>, but you can set it to <code>Float64</code> or any other type that can hold the frequency values.</p></li></ul><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply frequency encoding to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table.   Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>statistic_given_feat_val</code>: A dictionary that maps each level for each column in a subset of the categorical features of X into its frequency.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using MLJ

# Define categorical features
A = [&quot;g&quot;, &quot;b&quot;, &quot;g&quot;, &quot;r&quot;, &quot;r&quot;,]  
B = [1.0, 2.0, 3.0, 4.0, 5.0,]
C = [&quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;,]  
D = [true, false, true, false, true,]
E = [1, 2, 3, 4, 5,]

# Combine into a named tuple
X = (A = A, B = B, C = C, D = D, E = E)

# Coerce A, C, D to multiclass and B to continuous and E to ordinal
X = coerce(X,
:A =&gt; Multiclass,
:B =&gt; Continuous,
:C =&gt; Multiclass,
:D =&gt; Multiclass,
:E =&gt; OrderedFactor,
)

# Check scitype coercions:
schema(X)

encoder = FrequencyEncoder(ordered_factor = false, normalize=true)
mach = fit!(machine(encoder, X))
Xnew = transform(mach, X)

julia &gt; Xnew
    (A = [2, 1, 2, 2, 2],
    B = [1.0, 2.0, 3.0, 4.0, 5.0],
    C = [4, 4, 4, 1, 4],
    D = [3, 2, 3, 2, 3],
    E = CategoricalArrays.CategoricalValue{Int64, UInt32}[1, 2, 3, 4, 5],)</code></pre><p>See also <a href="../classical/#MLJTransforms.TargetEncoder"><code>TargetEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/encoders/frequency_encoding/interface_mlj.jl#L75-L99">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.TargetEncoder-transformers-all_transformers" href="#MLJTransforms.TargetEncoder-transformers-all_transformers"><code>MLJTransforms.TargetEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">TargetEncoder</code></pre><p>A model type for constructing a target encoder, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">TargetEncoder = @load TargetEncoder pkg=MLJTransforms</code></pre><p>Do <code>model = TargetEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>TargetEncoder(features=...)</code>.</p><p><code>TargetEncoder</code> implements target encoding as defined in [1] to encode categorical variables      into continuous ones using statistics from the target variable.</p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X, y)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><ul><li><code>y</code> is the target, which can be any <code>AbstractVector</code> whose element scitype is <code>Continuous</code> or <code>Count</code> for regression problems and  <code>Multiclass</code> or <code>OrderedFactor</code> for classification problems; check the scitype with <code>schema(y)</code></li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li><li><p><code>λ</code>: Shrinkage hyperparameter used to mix between posterior and prior statistics as described in [1]</p></li><li><p><code>m</code>: An integer hyperparameter to compute shrinkage as described in [1]. If <code>m=:auto</code> then m will be computed using</p></li></ul><p>empirical Bayes estimation as described in [1]</p><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply target encoding to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table.   Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>task</code>: Whether the task is <code>Classification</code> or <code>Regression</code></li><li><code>y_statistic_given_feat_level</code>: A dictionary with the necessary statistics to encode each categorical feature. It maps each    level in each categorical feature to a statistic computed over the target.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using MLJ

# Define categorical features
A = [&quot;g&quot;, &quot;b&quot;, &quot;g&quot;, &quot;r&quot;, &quot;r&quot;,]  
B = [1.0, 2.0, 3.0, 4.0, 5.0,]
C = [&quot;f&quot;, &quot;f&quot;, &quot;f&quot;, &quot;m&quot;, &quot;f&quot;,]  
D = [true, false, true, false, true,]
E = [1, 2, 3, 4, 5,]

# Define the target variable 
y = [&quot;c1&quot;, &quot;c2&quot;, &quot;c3&quot;, &quot;c1&quot;, &quot;c2&quot;,]

# Combine into a named tuple
X = (A = A, B = B, C = C, D = D, E = E)

# Coerce A, C, D to multiclass and B to continuous and E to ordinal
X = coerce(X,
:A =&gt; Multiclass,
:B =&gt; Continuous,
:C =&gt; Multiclass,
:D =&gt; Multiclass,
:E =&gt; OrderedFactor,
)
y = coerce(y, Multiclass)

encoder = TargetEncoder(ordered_factor = false, lambda = 1.0, m = 0,)
mach = fit!(machine(encoder, X, y))
Xnew = transform(mach, X)

julia &gt; schema(Xnew)
┌───────┬──────────────────┬─────────────────────────────────┐
│ names │ scitypes         │ types                           │
├───────┼──────────────────┼─────────────────────────────────┤
│ A_1   │ Continuous       │ Float64                         │
│ A_2   │ Continuous       │ Float64                         │
│ A_3   │ Continuous       │ Float64                         │
│ B     │ Continuous       │ Float64                         │
│ C_1   │ Continuous       │ Float64                         │
│ C_2   │ Continuous       │ Float64                         │
│ C_3   │ Continuous       │ Float64                         │
│ D_1   │ Continuous       │ Float64                         │
│ D_2   │ Continuous       │ Float64                         │
│ D_3   │ Continuous       │ Float64                         │
│ E     │ OrderedFactor{5} │ CategoricalValue{Int64, UInt32} │
└───────┴──────────────────┴─────────────────────────────────┘</code></pre><p><strong>Reference</strong></p><p>[1] Micci-Barreca, Daniele.      “A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems”      SIGKDD Explor. Newsl. 3, 1 (July 2001), 27–32.</p><p>See also <a href="../classical/#MLJTransforms.OneHotEncoder"><code>OneHotEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/encoders/target_encoding/interface_mlj.jl#L120-L144">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.ContrastEncoder-transformers-all_transformers" href="#MLJTransforms.ContrastEncoder-transformers-all_transformers"><code>MLJTransforms.ContrastEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ContrastEncoder</code></pre><p>A model type for constructing a contrast encoder, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">ContrastEncoder = @load ContrastEncoder pkg=MLJTransforms</code></pre><p>Do <code>model = ContrastEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>ContrastEncoder(features=...)</code>.</p><p><code>ContrastEncoder</code> implements the following contrast encoding methods for  categorical features: dummy, sum, backward/forward difference, and Helmert coding.  More generally, users can specify a custom contrast or hypothesis matrix, and each feature  can be encoded using a different method.</p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance unsupervised <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>mode=:dummy</code>: The type of encoding to use. Can be one of <code>:contrast</code>, <code>:dummy</code>, <code>:sum</code>, <code>:backward_diff</code>, <code>:forward_diff</code>, <code>:helmert</code> or <code>:hypothesis</code>.</p></li></ul><p>If <code>ignore=false</code> (features to be encoded are listed explictly in <code>features</code>), then this can be a vector of the same length as <code>features</code> to specify a different contrast encoding scheme for each feature</p><ul><li><code>buildmatrix=nothing</code>: A function or other callable with signature <code>buildmatrix(colname, k)</code>, </li></ul><p>where <code>colname</code> is the name of the feature levels and <code>k</code> is it&#39;s length, and which returns contrast or  hypothesis matrix with row/column ordering consistent with the ordering of <code>levels(col)</code>. Only relevant if <code>mode</code> is <code>:contrast</code> or <code>:hypothesis</code>.</p><ul><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li></ul><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply contrast encoding to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table. Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>vector_given_value_given_feature</code>: A dictionary that maps each level for each column in a subset of the categorical features of X into its frequency.</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">using MLJ

# Define categorical dataset
X = (
    name   = categorical([&quot;Ben&quot;, &quot;John&quot;, &quot;Mary&quot;, &quot;John&quot;]),
    height = [1.85, 1.67, 1.5, 1.67],
    favnum = categorical([7, 5, 10, 1]),
    age    = [23, 23, 14, 23],
)

# Check scitype coercions:
schema(X)

encoder =  ContrastEncoder(
    features = [:name, :favnum],
    ignore = false, 
    mode = [:dummy, :helmert],
)
mach = fit!(machine(encoder, X))
Xnew = transform(mach, X)

julia &gt; Xnew
    (name_John = [1.0, 0.0, 0.0, 0.0],
    name_Mary = [0.0, 1.0, 0.0, 1.0],
    height = [1.85, 1.67, 1.5, 1.67],
    favnum_5 = [0.0, 1.0, 0.0, -1.0],
    favnum_7 = [2.0, -1.0, 0.0, -1.0],
    favnum_10 = [-1.0, -1.0, 3.0, -1.0],
    age = [23, 23, 14, 23],)</code></pre><p>See also <a href="../classical/#MLJTransforms.OneHotEncoder"><code>OneHotEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/encoders/contrast_encoder/interface_mlj.jl#L73-L97">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.CardinalityReducer-transformers-all_transformers" href="#MLJTransforms.CardinalityReducer-transformers-all_transformers"><code>MLJTransforms.CardinalityReducer</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">CardinalityReducer</code></pre><p>A model type for constructing a cardinality reducer, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">CardinalityReducer = @load CardinalityReducer pkg=MLJTransforms</code></pre><p>Do <code>model = CardinalityReducer()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>CardinalityReducer(features=...)</code>.</p><p><code>CardinalityReducer</code> maps any level of a categorical feature that occurs with frequency &lt; <code>min_frequency</code> into a new level (e.g., &quot;Other&quot;). This is useful when some categorical features have high cardinality and many levels are infrequent. This assumes that the categorical features have raw types that are in <code>Union{AbstractString, Char, Number}</code>.</p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance unsupervised <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li><li><p><code>min_frequency::Real=3</code>: Any level of a categorical feature that occurs with frequency &lt; <code>min_frequency</code> will be mapped to a new level. Could be</p></li></ul><p>an integer or a float which decides whether raw counts or normalized frequencies are used.</p><ul><li><code>label_for_infrequent::Dict{&lt;:Type, &lt;:Any}()= Dict( AbstractString =&gt; &quot;Other&quot;, Char =&gt; &#39;O&#39;, )</code>: A</li></ul><p>dictionary where the possible values for keys are the types in <code>Char</code>, <code>AbstractString</code>, and <code>Number</code> and each value signifies the new level to map into given a column raw super type. By default, if the raw type of the column subtypes <code>AbstractString</code> then the new value is <code>&quot;Other&quot;</code> and if the raw type subtypes <code>Char</code> then the new value is <code>&#39;O&#39;</code> and if the raw type subtypes <code>Number</code> then the new value is the lowest value in the column - 1.</p><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply cardinality reduction to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table.   Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>new_cat_given_col_val</code>: A dictionary that maps each level in a   categorical feature to a new level (either itself or the new level specified in <code>label_for_infrequent</code>)</li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">import StatsBase.proportionmap
using MLJ

# Define categorical features
A = [ [&quot;a&quot; for i in 1:100]..., &quot;b&quot;, &quot;b&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;]
B = [ [0 for i in 1:100]..., 1, 2, 3, 4, 4]

# Combine into a named tuple
X = (A = A, B = B)

# Coerce A, C, D to multiclass and B to continuous and E to ordinal
X = coerce(X,
:A =&gt; Multiclass,
:B =&gt; Multiclass
)

encoder = CardinalityReducer(ordered_factor = false, min_frequency=3)
mach = fit!(machine(encoder, X))
Xnew = transform(mach, X)

julia&gt; proportionmap(Xnew.A)
Dict{CategoricalArrays.CategoricalValue{String, UInt32}, Float64} with 3 entries:
  &quot;Other&quot; =&gt; 0.0190476
  &quot;b&quot;     =&gt; 0.0285714
  &quot;a&quot;     =&gt; 0.952381

julia&gt; proportionmap(Xnew.B)
Dict{CategoricalArrays.CategoricalValue{Int64, UInt32}, Float64} with 2 entries:
  0  =&gt; 0.952381
  -1 =&gt; 0.047619</code></pre><p>See also <a href="../classical/#MLJTransforms.FrequencyEncoder"><code>FrequencyEncoder</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/transformers/cardinality_reducer/interface_mlj.jl#L88-L112">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="MLJTransforms.MissingnessEncoder-transformers-all_transformers" href="#MLJTransforms.MissingnessEncoder-transformers-all_transformers"><code>MLJTransforms.MissingnessEncoder</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MissingnessEncoder</code></pre><p>A model type for constructing a missingness encoder, based on <a href="https://github.com/JuliaAI/MLJTransforms.jl">MLJTransforms.jl</a>, and implementing the MLJ model interface.</p><p>From MLJ, the type can be imported using</p><pre><code class="nohighlight hljs">MissingnessEncoder = @load MissingnessEncoder pkg=MLJTransforms</code></pre><p>Do <code>model = MissingnessEncoder()</code> to construct an instance with default hyper-parameters. Provide keyword arguments to override hyper-parameter defaults, as in <code>MissingnessEncoder(features=...)</code>.</p><p><code>MissingnessEncoder</code> maps any missing level of a categorical feature into a new level (e.g., &quot;Missing&quot;).  By this, missingness will be treated as a new level by any subsequent model. This assumes that the categorical features have raw types that are in <code>Char</code>, <code>AbstractString</code>, and <code>Number</code>.</p><p><strong>Training data</strong></p><p>In MLJ (or MLJBase) bind an instance unsupervised <code>model</code> to data with</p><pre><code class="nohighlight hljs">mach = machine(model, X)</code></pre><p>Here:</p><ul><li><code>X</code> is any table of input features (eg, a <code>DataFrame</code>). Features to be transformed must  have element scitype <code>Multiclass</code> or <code>OrderedFactor</code>. Use <code>schema(X)</code> to   check scitypes. </li></ul><p>Train the machine using <code>fit!(mach, rows=...)</code>.</p><p><strong>Hyper-parameters</strong></p><ul><li><p><code>features=[]</code>: A list of names of categorical features given as symbols to exclude or include from encoding, according to the value of <code>ignore</code>, or a single symbol (which is treated as a vector with one symbol), or a callable that returns true for features to be included/excluded</p></li><li><p><code>ignore=true</code>: Whether to exclude or include the features given in <code>features</code></p></li><li><p><code>ordered_factor=false</code>: Whether to encode <code>OrderedFactor</code> or ignore them</p></li><li><p><code>label_for_missing::Dict{&lt;:Type, &lt;:Any}()= Dict( AbstractString =&gt; &quot;missing&quot;, Char =&gt; &#39;m&#39;, )</code>: A</p></li></ul><p>dictionary where the possible values for keys are the types in <code>Char</code>, <code>AbstractString</code>, and <code>Number</code> and where each value signifies the new level to map into given a column raw super type. By default, if the raw type of the column subtypes <code>AbstractString</code> then missing values will be replaced with <code>&quot;missing&quot;</code> and if the raw type subtypes <code>Char</code> then the new value is <code>&#39;m&#39;</code> and if the raw type subtypes <code>Number</code> then the new value is the lowest value in the column - 1.</p><p><strong>Operations</strong></p><ul><li><code>transform(mach, Xnew)</code>: Apply cardinality reduction to selected <code>Multiclass</code> or <code>OrderedFactor</code> features of <code>Xnew</code> specified by hyper-parameters, and   return the new table.   Features that are neither <code>Multiclass</code> nor <code>OrderedFactor</code>  are always left unchanged.</li></ul><p><strong>Fitted parameters</strong></p><p>The fields of <code>fitted_params(mach)</code> are:</p><ul><li><code>label_for_missing_given_feature</code>: A dictionary that for each column, maps <code>missing</code> into some value according to <code>label_for_missing</code></li></ul><p><strong>Report</strong></p><p>The fields of <code>report(mach)</code> are:</p><ul><li><code>encoded_features</code>: The subset of the categorical features of <code>X</code> that were encoded</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia hljs">import StatsBase.proportionmap
using MLJ

# Define a table with missing values
Xm = (
    A = categorical([&quot;Ben&quot;, &quot;John&quot;, missing, missing, &quot;Mary&quot;, &quot;John&quot;, missing]),
    B = [1.85, 1.67, missing, missing, 1.5, 1.67, missing],
    C= categorical([7, 5, missing, missing, 10, 0, missing]),
    D = [23, 23, 44, 66, 14, 23, 11],
    E = categorical([missing, &#39;g&#39;, &#39;r&#39;, missing, &#39;r&#39;, &#39;g&#39;, &#39;p&#39;])
)

encoder = MissingnessEncoder()
mach = fit!(machine(encoder, Xm))
Xnew = transform(mach, Xm)

julia&gt; Xnew
(A = [&quot;Ben&quot;, &quot;John&quot;, &quot;missing&quot;, &quot;missing&quot;, &quot;Mary&quot;, &quot;John&quot;, &quot;missing&quot;],
 B = Union{Missing, Float64}[1.85, 1.67, missing, missing, 1.5, 1.67, missing],
 C = [7, 5, -1, -1, 10, 0, -1],
 D = [23, 23, 44, 66, 14, 23, 11],
 E = [&#39;m&#39;, &#39;g&#39;, &#39;r&#39;, &#39;m&#39;, &#39;r&#39;, &#39;g&#39;, &#39;p&#39;],)
</code></pre><p>See also <a href="../utility/#MLJTransforms.CardinalityReducer"><code>CardinalityReducer</code></a></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/f487c592886a5e5f9bf254fe2c24538f26baf418/src/encoders/missingness_encoding/interface_mlj.jl#L77-L101">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../">« Introduction</a><a class="docs-footer-nextpage" href="../classical/">Classical Encoders »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Sunday 24 August 2025 03:19">Sunday 24 August 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
