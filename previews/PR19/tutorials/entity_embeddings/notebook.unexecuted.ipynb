{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Entity Embeddi# ## Package Setup and Environment"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__);\n",
    "Pkg.instantiate();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Julia version** is assumed to be 1.10.*\n",
    "\n",
    "## Required Packages\n",
    "\n",
    "We'll need several packages for this tutorial:\n",
    "- **MLJ ecosystem**: Core machine learning framework and MLJFlux for neural networks\n",
    "- **Flux**: Deep learning framework for building the embedding models\n",
    "- **Data handling**: CSV, DataFrames, CategoricalArrays for data manipulation\n",
    "- **Visualization**: Plots for visualizing the learned embeddings\n",
    "- **Utilities**: Random, Tables, ProgressMeter, StatsBase for various helper functionsedder\n",
    "\n",
    "This demonstration is available as a Jupyter notebook or julia script\n",
    "[here](https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/common_workflows/entity_embeddings).\n",
    "\n",
    "Entity embedding is a newer deep learning approach for categorical encoding introduced in 2016 by Cheng Guo and Felix Berkhahn.\n",
    "It employs a set of embedding layers to map each categorical feature into a dense continuous vector in a similar fashion to how they are employed in NLP architectures.\n",
    "\n",
    "In MLJFlux, the `EntityEmbedder` provides a high-level interface to learn entity embeddings using any supervised MLJFlux model as the underlying learner.\n",
    "The embedder can be used as a transformer in MLJ pipelines to encode categorical features with learned embeddings, which can then be used as features in downstream machine learning models.\n",
    "\n",
    "In this tutorial, we will explore how to use the `EntityEmbedder` to learn and apply entity embeddings on the Google Play Store dataset.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the concept of entity embeddings for categorical encoding\n",
    "- Learn how to use `EntityEmbedder` from MLJFlux\n",
    "- Apply entity embeddings to a real-world dataset\n",
    "- Visualize the learned embedding spaces\n",
    "- Build pipelines combining embeddings with downstream models"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__);\n",
    "Pkg.instantiate();\n",
    "\n",
    "\n",
    "\n",
    "# Import all required packages\n",
    "using MLJ\n",
    "using Flux\n",
    "using Optimisers\n",
    "using CategoricalArrays\n",
    "using DataFrames\n",
    "using Random\n",
    "using Tables\n",
    "using ProgressMeter\n",
    "using Plots\n",
    "using ScientificTypes\n",
    "using CSV\n",
    "using StatsBase  ## For countmap\n",
    "import Plots: mm  ## For margin units"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "We'll use the Google Play Store dataset which contains information about mobile applications.\n",
    "This dataset has several categorical features that are perfect for demonstrating entity embeddings:\n",
    "- **Category**: App category (e.g., Games, Social, Tools)\n",
    "- **Content Rating**: Age rating (e.g., Everyone, Teen, Mature)\n",
    "- **Genres**: Primary genre of the app\n",
    "- **Android Ver**: Required Android version\n",
    "- **Type**: Free or Paid"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Load the Google Play Store dataset\n",
    "df = CSV.read(\"./googleplaystore.csv\", DataFrame)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Cleaning and Type Conversion\n",
    "\n",
    "The raw dataset requires significant cleaning. We'll handle:\n",
    "1. **Reviews**: Convert to integers\n",
    "2. **Size**: Parse size strings like \"14M\", \"512k\" to numeric values\n",
    "3. **Installs**: Remove formatting characters and convert to integers\n",
    "4. **Price**: Remove dollar signs and convert to numeric\n",
    "5. **Genres**: Extract primary genre only"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Custom parsing function that returns missing instead of nothing\n",
    "safe_parse(T, s) = something(tryparse(T, s), missing)\n",
    "\n",
    "# Reviews: ensure integer\n",
    "df.Reviews = safe_parse.(Int, string.(df.Reviews))\n",
    "\n",
    "# Size: \"14M\", \"512k\", or \"Varies with device\"\n",
    "function parse_size(s)\n",
    "    if s == \"Varies with device\"\n",
    "        return missing\n",
    "    elseif occursin('M', s)\n",
    "        return safe_parse(Float64, replace(s, \"M\" => \"\")) * 1_000_000\n",
    "    elseif occursin('k', s)\n",
    "        return safe_parse(Float64, replace(s, \"k\" => \"\")) * 1_000\n",
    "    else\n",
    "        return safe_parse(Float64, s)\n",
    "    end\n",
    "end\n",
    "df.Size = parse_size.(string.(df.Size))\n",
    "\n",
    "# Installs: strip '+' and ',' then parse\n",
    "clean_installs = replace.(string.(df.Installs), r\"[+,]\" => \"\")\n",
    "df.Installs = safe_parse.(Int, clean_installs)\n",
    "\n",
    "# Price: strip leading '$'\n",
    "df.Price = safe_parse.(Float64, replace.(string.(df.Price), r\"^\\$\" => \"\"))\n",
    "\n",
    "# Genres: take only the primary genre\n",
    "df.Genres = first.(split.(string.(df.Genres), ';'))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Storing Category Information for Visualization\n",
    "\n",
    "We'll store the unique values of each categorical feature to use later when visualizing the embeddings."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Store unique category names for visualization later\n",
    "category_names = Dict(\n",
    "    :Category => sort(unique(df.Category)),\n",
    "    Symbol(\"Content Rating\") => sort(unique(df[!, Symbol(\"Content Rating\")])),\n",
    "    :Genres => sort(unique(df.Genres)),\n",
    "    Symbol(\"Android Ver\") => sort(unique(df[!, Symbol(\"Android Ver\")])),\n",
    ")\n",
    "\n",
    "println(\"Category names extracted:\")\n",
    "for (feature, names) in category_names\n",
    "    println(\"$feature: $(length(names)) categories\")\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Selection and Missing Value Handling\n",
    "\n",
    "We'll select the most relevant features and remove any rows with missing values to ensure clean data for our embedding model."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "select!(\n",
    "    df,\n",
    "    [\n",
    "        :Category, :Reviews, :Size, :Installs, :Type,\n",
    "        :Price, Symbol(\"Content Rating\"), :Genres, Symbol(\"Android Ver\"), :Rating,\n",
    "    ],\n",
    ")\n",
    "dropmissing!(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Categorical Target Variable\n",
    "\n",
    "For this tutorial, we'll convert the continuous rating into a categorical classification problem.\n",
    "This will allow us to use a classification model that can learn meaningful embeddings.\n",
    "\n",
    "We'll create 10 rating categories by rounding to the nearest 0.5 (e.g., 0.0, 0.5, 1.0, ..., 4.5, 5.0)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Create 10 classes: 0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5\n",
    "function rating_to_categorical(rating)\n",
    "    # Clamp rating to valid range and round to nearest 0.5\n",
    "    clamped_rating = clamp(rating, 0.0, 5.0)\n",
    "    rounded_rating = round(clamped_rating * 2) / 2  ## Round to nearest 0.5\n",
    "    return string(rounded_rating)\n",
    "end\n",
    "\n",
    "# Apply the transformation\n",
    "df.RatingCategory = categorical([rating_to_categorical(r) for r in df.Rating])\n",
    "\n",
    "# Check the distribution of categorical rating labels\n",
    "println(\"Distribution of categorical rating labels:\")\n",
    "println(sort(countmap(df.RatingCategory)))\n",
    "println(\"\\nUnique rating categories: $(sort(unique(df.RatingCategory)))\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Type Coercion for MLJ\n",
    "\n",
    "MLJ requires explicit type coercion to understand which columns are categorical vs continuous.\n",
    "This step is crucial for the `EntityEmbedder` to identify which features need embedding layers."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Coerce types for MLJ compatibility\n",
    "df = coerce(df,\n",
    "    :Category => Multiclass,\n",
    "    :Reviews => Continuous,\n",
    "    :Size => Continuous,\n",
    "    :Installs => Continuous,\n",
    "    :Type => Multiclass,\n",
    "    :Price => Continuous,\n",
    "    Symbol(\"Content Rating\") => Multiclass,\n",
    "    :Genres => Multiclass,\n",
    "    Symbol(\"Android Ver\") => Multiclass,\n",
    "    :Rating => Continuous,  ## Keep original for reference\n",
    "    :RatingCategory => Multiclass,  ## New categorical target\n",
    ")\n",
    "schema(df)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Splitting\n",
    "\n",
    "We'll split our data into training and testing sets using stratified sampling to ensure balanced representation of rating categories."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Split into features and target\n",
    "y = df[!, :RatingCategory]  ## Use categorical rating as target\n",
    "X = select(df, Not([:Rating, :RatingCategory]))  ## Exclude both rating columns from features\n",
    "\n",
    "# Split the data with stratification\n",
    "(X_train, X_test), (y_train, y_test) = partition(\n",
    "    (X, y),\n",
    "    0.8,\n",
    "    multi = true,\n",
    "    shuffle = true,\n",
    "    stratify = y,\n",
    "    rng = Random.Xoshiro(41),\n",
    ");\n",
    "\n",
    "using MLJFlux"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building the EntityEmbedder Model\n",
    "\n",
    "The `EntityEmbedder` works by wrapping a supervised learning model that will learn embeddings as part of its training process.\n",
    "\n",
    "### Key Components:\n",
    "1. **Base Model**: A neural network classifier that learns to predict our target\n",
    "2. **Embedding Dimensions**: We specify how many dimensions each categorical feature should be embedded into\n",
    "3. **Architecture**: The embeddings are learned jointly with the prediction task\n",
    "\n",
    "### Why Entity Embeddings Work:\n",
    "- Similar categories get mapped to similar vectors in the embedding space\n",
    "- The embedding captures semantic relationships between categories\n",
    "- Dimensionality reduction helps with the curse of dimensionality\n",
    "- Learned representations often generalize better than one-hot encoding"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Load the neural network classifier\n",
    "NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg = MLJFlux"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuring the Base Neural Network\n",
    "\n",
    "We'll create a neural network classifier with custom embedding dimensions for each categorical feature.\n",
    "Setting smaller embedding dimensions (like 2D) makes it easier to visualize the learned representations."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Create the underlying supervised model that will learn the embeddings\n",
    "base_clf = NeuralNetworkClassifier(\n",
    "    builder = MLJFlux.Short(n_hidden = 14),\n",
    "    optimiser = Optimisers.Adam(10e-2),\n",
    "    batch_size = 20,\n",
    "    epochs = 5,\n",
    "    acceleration = CUDALibs(),\n",
    "    embedding_dims = Dict(\n",
    "        :Category => 2,\n",
    "        :Type => 2,\n",
    "        Symbol(\"Content Rating\") => 2,\n",
    "        :Genres => 2,\n",
    "        Symbol(\"Android Ver\") => 2,\n",
    "    ),\n",
    "    rng = 39,\n",
    ")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the EntityEmbedder\n",
    "\n",
    "The `EntityEmbedder` wraps our neural network and can be used as a transformer in MLJ pipelines.\n",
    "By default, it uses `min(n_categories - 1, 10)` dimensions for any categorical feature not explicitly specified."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Create the EntityEmbedder using the neural network\n",
    "embedder = EntityEmbedder(base_clf)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the EntityEmbedder\n",
    "\n",
    "Now we'll train the embedder on our training data. The model learns to predict app ratings while simultaneously learning meaningful embeddings for categorical features.\n",
    "\n",
    "### What Happens During Training:\n",
    "1. Each categorical value gets mapped to a learnable embedding vector\n",
    "2. The neural network learns to predict ratings using these embeddings + continuous features\n",
    "3. Similar categories that lead to similar predictions get similar embedding vectors\n",
    "4. The embeddings capture semantic relationships in the data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Create and train the machine\n",
    "mach = machine(embedder, X_train, y_train)\n",
    "MLJ.fit!(mach, force = true, verbosity = 1)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Transforming Data with Learned Embeddings\n",
    "\n",
    "After training, we can use the embedder as a transformer to convert categorical features into their learned embedding representations."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Transform the data using the learned embeddings\n",
    "X_train_embedded = MLJFlux.transform(mach, X_train)\n",
    "X_test_embedded = MLJFlux.transform(mach, X_test)\n",
    "\n",
    "# Check the schema transformation\n",
    "println(\"Original schema:\")\n",
    "schema(X_train)\n",
    "println(\"\\nEmbedded schema:\")\n",
    "schema(X_train_embedded)\n",
    "X_train_embedded"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using Embeddings in ML Pipelines\n",
    "\n",
    "One of the key advantages of entity embeddings is that they can be used as features in any downstream machine learning model.\n",
    "Let's create a pipeline that combines our `EntityEmbedder` with a k-nearest neighbors classifier.\n",
    "\n",
    "### Pipeline Benefits:\n",
    "- **Modular**: Easy to swap out different downstream models\n",
    "- **Reusable**: Embeddings learned once can be used with multiple models\n",
    "- **Interpretable**: Can analyze embedding spaces separately from final predictions"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Load KNN classifier\n",
    "KNNClassifier = @load KNNClassifier pkg = NearestNeighborModels\n",
    "\n",
    "# Create a pipeline: EntityEmbedder -> KNNClassifier\n",
    "pipe = embedder |> KNNClassifier(K = 5)\n",
    "\n",
    "# Train the pipeline\n",
    "pipe_mach = machine(pipe, X_train, y_train)\n",
    "MLJ.fit!(pipe_mach, verbosity = 0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualizing the Learned Embedding Spaces\n",
    "\n",
    "One of the most powerful aspects of entity embeddings is their interpretability. Since we used 2D embeddings, we can visualize how the model has organized different categories in the embedding space.\n",
    "\n",
    "### What to Look For:\n",
    "- **Clustering**: Similar categories should be close together\n",
    "- **Separation**: Different types of categories should be well-separated\n",
    "- **Meaningful patterns**: The spatial arrangement should reflect semantic relationships"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Extract the learned embedding matrices from the fitted model\n",
    "mapping_matrices = fitted_params(mach)[4]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating Embedding Visualization Function\n",
    "\n",
    "We'll create a helper function to plot the 2D embedding space for each categorical feature.\n",
    "Each point represents a category, and its position shows how the model learned to represent it."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Function to create and display scatter plot for categorical embeddings\n",
    "function plot_categorical_embeddings(feature_name, feature_categories, embedding_matrix)\n",
    "    # Create scatter plot for this feature's embeddings\n",
    "    p = scatter(embedding_matrix[1, :], embedding_matrix[2, :],\n",
    "        title = \"$(feature_name) Embeddings\",\n",
    "        xlabel = \"Dimension 1\",\n",
    "        ylabel = \"Dimension 2\",\n",
    "        label = \"$(feature_name)\",\n",
    "        legend = :topright,\n",
    "        markersize = 8,\n",
    "        size = (1200, 600))\n",
    "\n",
    "    # Annotate each point with the actual category name\n",
    "    for (i, col) in enumerate(eachcol(embedding_matrix))\n",
    "        if i <= length(feature_categories)\n",
    "            cat_name = string(feature_categories[i])\n",
    "            # Truncate long category names for readability\n",
    "            display_name = length(cat_name) > 10 ? cat_name[1:10] * \"...\" : cat_name\n",
    "            annotate!(p, col[1] + 0.02, col[2] + 0.02, text(display_name, :black, 5))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # Display the plot\n",
    "    display(p)\n",
    "    println(\"Displayed embedding plot for: $(feature_name)\")\n",
    "    return p\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generating Embedding Plots for Each Categorical Feature\n",
    "\n",
    "Let's visualize the embedding space for each of our categorical features to understand what patterns the model learned."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Create separate plots for each categorical feature's embeddings\n",
    "\n",
    "# Plot 1: Category embeddings\n",
    "if haskey(mapping_matrices, :Category)\n",
    "    plot_categorical_embeddings(\n",
    "        :Category,\n",
    "        category_names[:Category],\n",
    "        mapping_matrices[:Category],\n",
    "    )\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that pairs such as social and entertainment, shopping and finance, and comics and art are closer together than others."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Plot 2: Content Rating embeddings\n",
    "if haskey(mapping_matrices, Symbol(\"Content Rating\"))\n",
    "    plot_categorical_embeddings(\n",
    "        Symbol(\"Content Rating\"),\n",
    "        category_names[Symbol(\"Content Rating\")],\n",
    "        mapping_matrices[Symbol(\"Content Rating\")],\n",
    "    )\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `Everyone` category is positioned far from all others."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Plot 3: Genres embeddings\n",
    "if haskey(mapping_matrices, :Genres)\n",
    "    plot_categorical_embeddings(:Genres, category_names[:Genres], mapping_matrices[:Genres])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the results may be less interpretable; the idea is that for purposes of indetifying the rating, the model considered categories closer together as more similar."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Plot 4: Android Ver embeddings\n",
    "if haskey(mapping_matrices, Symbol(\"Android Ver\"))\n",
    "    plot_categorical_embeddings(\n",
    "        Symbol(\"Android Ver\"),\n",
    "        category_names[Symbol(\"Android Ver\")],\n",
    "        mapping_matrices[Symbol(\"Android Ver\")],\n",
    "    )\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clear patterns like close proximity between (7.1 and up) and, 7.0-7.1"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "# Plot 5: Type embeddings (if it exists in the mapping)\n",
    "if haskey(mapping_matrices, :Type)\n",
    "    plot_categorical_embeddings(:Type, sort(unique(df.Type)), mapping_matrices[:Type])\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Indeed, `Free` and `Paid` are too dissimilar."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This demonstrates the power of entity embeddings as a modern approach to categorical feature encoding that goes beyond traditional methods like one-hot encoding or label encoding."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  },
  "kernelspec": {
   "name": "julia-1.11",
   "display_name": "Julia 1.11.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
