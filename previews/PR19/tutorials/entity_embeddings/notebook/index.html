<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Entity Embeddings Tutorial Â· MLJTransforms</title><meta name="title" content="Entity Embeddings Tutorial Â· MLJTransforms"/><meta property="og:title" content="Entity Embeddings Tutorial Â· MLJTransforms"/><meta property="twitter:title" content="Entity Embeddings Tutorial Â· MLJTransforms"/><meta name="description" content="Documentation for MLJTransforms."/><meta property="og:description" content="Documentation for MLJTransforms."/><meta property="twitter:description" content="Documentation for MLJTransforms."/><script data-outdated-warner src="../../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../../assets/documenter.js"></script><script src="../../../search_index.js"></script><script src="../../../siteinfo.js"></script><script src="../../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../../assets/themeswap.js"></script><link href="../../../assets/favicon.ico" rel="icon" type="image/x-icon"/><link href="https://fonts.googleapis.com/css2?family=Lato:ital,wght@0,100;0,300;0,400;0,700;0,900;1,100;1,300;1,400;1,700;1,900&amp;display=swap" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/all.min.css" rel="stylesheet" type="text/css"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../../"><img src="../../../assets/logo.gif" alt="MLJTransforms logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../../">MLJTransforms</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../../">Introduction</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Transformers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../transformers/all_transformers/">All Transformers</a></li><li><input class="collapse-toggle" id="menuitem-2-2" type="checkbox"/><label class="tocitem" for="menuitem-2-2"><span class="docs-label">Encoders</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../../transformers/classical/">Classical Encoders</a></li><li><a class="tocitem" href="../../../transformers/neural/">Neural-based Encoders</a></li><li><a class="tocitem" href="../../../transformers/contrast/">Contrast Encoders</a></li><li><a class="tocitem" href="../../../transformers/utility/">Utility Encoders</a></li></ul></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox" checked/><label class="tocitem" for="menuitem-3"><span class="docs-label">Extended Examples</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../standardization/notebook/">Standardization Impact</a></li><li><a class="tocitem" href="../../classic_comparison/notebook/">Milk Quality Classification</a></li><li><a class="tocitem" href="../../wine_example/notebook/">Wine Quality Prediction</a></li><li class="is-active"><a class="tocitem" href>Entity Embeddings Tutorial</a><ul class="internal"><li><a class="tocitem" href="#Learning-Objectives"><span>Learning Objectives</span></a></li><li><a class="tocitem" href="#Data-Loading-and-Preprocessing"><span>Data Loading and Preprocessing</span></a></li><li><a class="tocitem" href="#Building-the-EntityEmbedder-Model"><span>Building the EntityEmbedder Model</span></a></li><li><a class="tocitem" href="#Training-the-EntityEmbedder"><span>Training the EntityEmbedder</span></a></li><li><a class="tocitem" href="#Using-Embeddings-in-ML-Pipelines"><span>Using Embeddings in ML Pipelines</span></a></li><li><a class="tocitem" href="#Visualizing-the-Learned-Embedding-Spaces"><span>Visualizing the Learned Embedding Spaces</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../../contributing/">Contributing</a></li><li><a class="tocitem" href="../../../about/">About</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Extended Examples</a></li><li class="is-active"><a href>Entity Embeddings Tutorial</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Entity Embeddings Tutorial</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJTransforms.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands">ï‚›</span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/JuliaAI/MLJTransforms.jl/blob/dev/docs/src/tutorials/entity_embeddings/notebook.jl" title="Edit source on GitHub"><span class="docs-icon fa-solid">ï„</span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Entity-Embeddings-Tutorial"><a class="docs-heading-anchor" href="#Entity-Embeddings-Tutorial">Entity Embeddings Tutorial</a><a id="Entity-Embeddings-Tutorial-1"></a><a class="docs-heading-anchor-permalink" href="#Entity-Embeddings-Tutorial" title="Permalink"></a></h1><p><strong>Julia version</strong> is assumed to be 1.10.*</p><p>This demonstration is available as a Jupyter notebook or julia script (as well as the dataset) <a href="https://github.com/FluxML/MLJFlux.jl/tree/dev/docs/src/common_workflows/entity_embeddings">here</a>.</p><p>Entity embedding is a newer deep learning approach for categorical encoding introduced in 2016 by Cheng Guo and Felix Berkhahn. It employs a set of embedding layers to map each categorical feature into a dense continuous vector in a similar fashion to how they are employed in NLP architectures.</p><p>In MLJFlux, the <code>EntityEmbedder</code> provides a high-level interface to learn entity embeddings using any supervised MLJFlux model as the underlying learner. The embedder can be used as a transformer in MLJ pipelines to encode categorical features with learned embeddings, which can then be used as features in downstream machine learning models.</p><p>In this tutorial, we will explore how to use the <code>EntityEmbedder</code> to learn and apply entity embeddings on the Google Play Store dataset.</p><h2 id="Learning-Objectives"><a class="docs-heading-anchor" href="#Learning-Objectives">Learning Objectives</a><a id="Learning-Objectives-1"></a><a class="docs-heading-anchor-permalink" href="#Learning-Objectives" title="Permalink"></a></h2><ul><li>Understand the concept of entity embeddings for categorical encoding</li><li>Learn how to use <code>EntityEmbedder</code> from MLJFlux</li><li>Apply entity embeddings to a real-world dataset</li><li>Visualize the learned embedding spaces</li><li>Build pipelines combining embeddings with downstream models</li></ul><pre><code class="language-julia hljs">using Pkg;
Pkg.activate(@__DIR__);



# Import all required packages
using MLJ
using CategoricalArrays
using DataFrames
using Optimisers
using Random
using Tables
using ProgressMeter
using Plots
using ScientificTypes
using CSV
using StatsBase  ## For countmap
import Plots: mm  ## For margin units</code></pre><pre><code class="nohighlight hljs">  Activating project at `~/Documents/GitHub/MLJTransforms/docs/src/tutorials/entity_embeddings`
</code></pre><h2 id="Data-Loading-and-Preprocessing"><a class="docs-heading-anchor" href="#Data-Loading-and-Preprocessing">Data Loading and Preprocessing</a><a id="Data-Loading-and-Preprocessing-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Loading-and-Preprocessing" title="Permalink"></a></h2><p>We&#39;ll use the Google Play Store dataset which contains information about mobile applications. This dataset has several categorical features that are perfect for demonstrating entity embeddings:</p><ul><li><strong>Category</strong>: App category (e.g., Games, Social, Tools)</li><li><strong>Content Rating</strong>: Age rating (e.g., Everyone, Teen, Mature)</li><li><strong>Genres</strong>: Primary genre of the app</li><li><strong>Android Ver</strong>: Required Android version</li><li><strong>Type</strong>: Free or Paid</li></ul><pre><code class="language-julia hljs"># Load the Google Play Store dataset
df = CSV.read(&quot;./googleplaystore.csv&quot;, DataFrame);</code></pre><pre><code class="nohighlight hljs">â”Œ Warning: thread = 1 warning: only found 12 / 13 columns around data row: 10473. Filling remaining columns with `missing`
â”” @ CSV ~/.julia/packages/CSV/XLcqT/src/file.jl:592
â”Œ Warning: thread = 1 warning: only found 12 / 13 columns around data row: 10473. Filling remaining columns with `missing`
â”” @ CSV ~/.julia/packages/CSV/XLcqT/src/file.jl:592
</code></pre><h3 id="Data-Cleaning-and-Type-Conversion"><a class="docs-heading-anchor" href="#Data-Cleaning-and-Type-Conversion">Data Cleaning and Type Conversion</a><a id="Data-Cleaning-and-Type-Conversion-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Cleaning-and-Type-Conversion" title="Permalink"></a></h3><p>The raw dataset requires significant cleaning. We&#39;ll handle:</p><ol><li><strong>Reviews</strong>: Convert to integers</li><li><strong>Size</strong>: Parse size strings like &quot;14M&quot;, &quot;512k&quot; to numeric values</li><li><strong>Installs</strong>: Remove formatting characters and convert to integers</li><li><strong>Price</strong>: Remove dollar signs and convert to numeric</li><li><strong>Genres</strong>: Extract primary genre only</li></ol><pre><code class="language-julia hljs"># Custom parsing function that returns missing instead of nothing
safe_parse(T, s) = something(tryparse(T, s), missing);

# Reviews: ensure integer
df.Reviews = safe_parse.(Int, string.(df.Reviews));

# Size: &quot;14M&quot;, &quot;512k&quot;, or &quot;Varies with device&quot;
function parse_size(s)
    if s == &quot;Varies with device&quot;
        return missing
    elseif occursin(&#39;M&#39;, s)
        return safe_parse(Float64, replace(s, &quot;M&quot; =&gt; &quot;&quot;)) * 1_000_000
    elseif occursin(&#39;k&#39;, s)
        return safe_parse(Float64, replace(s, &quot;k&quot; =&gt; &quot;&quot;)) * 1_000
    else
        return safe_parse(Float64, s)
    end
end
df.Size = parse_size.(string.(df.Size));

# Installs: strip &#39;+&#39; and &#39;,&#39; then parse
clean_installs = replace.(string.(df.Installs), r&quot;[+,]&quot; =&gt; &quot;&quot;)
df.Installs = safe_parse.(Int, clean_installs);

# Price: strip leading &#39;$&#39;
df.Price = safe_parse.(Float64, replace.(string.(df.Price), r&quot;^\$&quot; =&gt; &quot;&quot;));

# Genres: take only the primary genre
df.Genres = first.(split.(string.(df.Genres), &#39;;&#39;));</code></pre><h3 id="Storing-Category-Information-for-Visualization"><a class="docs-heading-anchor" href="#Storing-Category-Information-for-Visualization">Storing Category Information for Visualization</a><a id="Storing-Category-Information-for-Visualization-1"></a><a class="docs-heading-anchor-permalink" href="#Storing-Category-Information-for-Visualization" title="Permalink"></a></h3><p>We&#39;ll store the unique values of each categorical feature to use later when visualizing the embeddings.</p><pre><code class="language-julia hljs"># Store unique category names for visualization later
category_names = Dict(
    :Category =&gt; sort(unique(df.Category)),
    Symbol(&quot;Content Rating&quot;) =&gt; sort(unique(df[!, Symbol(&quot;Content Rating&quot;)])),
    :Genres =&gt; sort(unique(df.Genres)),
    Symbol(&quot;Android Ver&quot;) =&gt; sort(unique(df[!, Symbol(&quot;Android Ver&quot;)])),
);

println(&quot;Category names extracted:&quot;)
for (feature, names) in category_names
    println(&quot;$feature: $(length(names)) categories&quot;)
end</code></pre><pre><code class="nohighlight hljs">Category names extracted:
Category: 34 categories
Content Rating: 7 categories
Android Ver: 35 categories
Genres: 49 categories
</code></pre><h3 id="Feature-Selection-and-Missing-Value-Handling"><a class="docs-heading-anchor" href="#Feature-Selection-and-Missing-Value-Handling">Feature Selection and Missing Value Handling</a><a id="Feature-Selection-and-Missing-Value-Handling-1"></a><a class="docs-heading-anchor-permalink" href="#Feature-Selection-and-Missing-Value-Handling" title="Permalink"></a></h3><p>We&#39;ll select the most relevant features and remove any rows with missing values to ensure clean data for our embedding model.</p><pre><code class="language-julia hljs">select!(
    df,
    [
        :Category, :Reviews, :Size, :Installs, :Type,
        :Price, Symbol(&quot;Content Rating&quot;), :Genres, Symbol(&quot;Android Ver&quot;), :Rating,
    ],
);
dropmissing!(df);</code></pre><h3 id="Creating-Categorical-Target-Variable"><a class="docs-heading-anchor" href="#Creating-Categorical-Target-Variable">Creating Categorical Target Variable</a><a id="Creating-Categorical-Target-Variable-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-Categorical-Target-Variable" title="Permalink"></a></h3><p>For this tutorial, we&#39;ll convert the continuous rating into a categorical classification problem. This will allow us to use a classification model that can learn meaningful embeddings.</p><p>We&#39;ll create 10 rating categories by rounding to the nearest 0.5 (e.g., 0.0, 0.5, 1.0, ..., 4.5, 5.0).</p><pre><code class="language-julia hljs"># Create 10 classes: 0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 4.5
function rating_to_categorical(rating)
    # Clamp rating to valid range and round to nearest 0.5
    clamped_rating = clamp(rating, 0.0, 5.0)
    rounded_rating = round(clamped_rating * 2) / 2  ## Round to nearest 0.5
    return string(rounded_rating)
end

# Apply the transformation
df.RatingCategory = categorical([rating_to_categorical(r) for r in df.Rating]);

# Check the distribution of categorical rating labels
println(&quot;Distribution of categorical rating labels:&quot;)
println(sort(countmap(df.RatingCategory)))
println(&quot;\nUnique rating categories: $(sort(unique(df.RatingCategory)))&quot;)</code></pre><pre><code class="nohighlight hljs">Distribution of categorical rating labels:
OrderedCollections.OrderedDict{CategoricalArrays.CategoricalValue{String, UInt32}, Int64}(&quot;1.0&quot; =&gt; 17, &quot;1.5&quot; =&gt; 18, &quot;2.0&quot; =&gt; 53, &quot;2.5&quot; =&gt; 105, &quot;3.0&quot; =&gt; 281, &quot;3.5&quot; =&gt; 722, &quot;4.0&quot; =&gt; 2420, &quot;4.5&quot; =&gt; 3542, &quot;5.0&quot; =&gt; 571, &quot;NaN&quot; =&gt; 1416)

Unique rating categories: [&quot;1.0&quot;, &quot;1.5&quot;, &quot;2.0&quot;, &quot;2.5&quot;, &quot;3.0&quot;, &quot;3.5&quot;, &quot;4.0&quot;, &quot;4.5&quot;, &quot;5.0&quot;, &quot;NaN&quot;]
</code></pre><h3 id="Type-Coercion-for-MLJ"><a class="docs-heading-anchor" href="#Type-Coercion-for-MLJ">Type Coercion for MLJ</a><a id="Type-Coercion-for-MLJ-1"></a><a class="docs-heading-anchor-permalink" href="#Type-Coercion-for-MLJ" title="Permalink"></a></h3><p>MLJ requires explicit type coercion to understand which columns are categorical vs continuous. This step is crucial for the <code>EntityEmbedder</code> to identify which features need embedding layers.</p><pre><code class="language-julia hljs"># Coerce types for MLJ compatibility
df = coerce(df,
    :Category =&gt; Multiclass,
    :Reviews =&gt; Continuous,
    :Size =&gt; Continuous,
    :Installs =&gt; Continuous,
    :Type =&gt; Multiclass,
    :Price =&gt; Continuous,
    Symbol(&quot;Content Rating&quot;) =&gt; Multiclass,
    :Genres =&gt; Multiclass,
    Symbol(&quot;Android Ver&quot;) =&gt; Multiclass,
    :Rating =&gt; Continuous,  ## Keep original for reference
    :RatingCategory =&gt; Multiclass,  ## New categorical target
);
schema(df)</code></pre><pre><code class="nohighlight hljs">â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ names          â”‚ scitypes       â”‚ types                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Category       â”‚ Multiclass{33} â”‚ CategoricalValue{String31, UInt32} â”‚
â”‚ Reviews        â”‚ Continuous     â”‚ Float64                            â”‚
â”‚ Size           â”‚ Continuous     â”‚ Float64                            â”‚
â”‚ Installs       â”‚ Continuous     â”‚ Float64                            â”‚
â”‚ Type           â”‚ Multiclass{2}  â”‚ CategoricalValue{String7, UInt32}  â”‚
â”‚ Price          â”‚ Continuous     â”‚ Float64                            â”‚
â”‚ Content Rating â”‚ Multiclass{6}  â”‚ CategoricalValue{String15, UInt32} â”‚
â”‚ Genres         â”‚ Multiclass{48} â”‚ CategoricalValue{String, UInt32}   â”‚
â”‚ Android Ver    â”‚ Multiclass{34} â”‚ CategoricalValue{String31, UInt32} â”‚
â”‚ Rating         â”‚ Continuous     â”‚ Float64                            â”‚
â”‚ RatingCategory â”‚ Multiclass{10} â”‚ CategoricalValue{String, UInt32}   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</code></pre><h3 id="Data-Splitting"><a class="docs-heading-anchor" href="#Data-Splitting">Data Splitting</a><a id="Data-Splitting-1"></a><a class="docs-heading-anchor-permalink" href="#Data-Splitting" title="Permalink"></a></h3><p>We&#39;ll split our data into training and testing sets using stratified sampling to ensure balanced representation of rating categories.</p><pre><code class="language-julia hljs"># Split into features and target
y = df[!, :RatingCategory]  ## Use categorical rating as target
X = select(df, Not([:Rating, :RatingCategory]));  ## Exclude both rating columns from features

# Split the data with stratification
(X_train, X_test), (y_train, y_test) = partition(
    (X, y),
    0.8,
    multi = true,
    shuffle = true,
    stratify = y,
    rng = Random.Xoshiro(41),
);

using MLJFlux</code></pre><h2 id="Building-the-EntityEmbedder-Model"><a class="docs-heading-anchor" href="#Building-the-EntityEmbedder-Model">Building the EntityEmbedder Model</a><a id="Building-the-EntityEmbedder-Model-1"></a><a class="docs-heading-anchor-permalink" href="#Building-the-EntityEmbedder-Model" title="Permalink"></a></h2><pre><code class="language-julia hljs"># Load the neural network classifier
NeuralNetworkClassifier = @load NeuralNetworkClassifier pkg = MLJFlux</code></pre><pre><code class="nohighlight hljs">MLJFlux.NeuralNetworkClassifier</code></pre><h3 id="Configuring-the-Base-Neural-Network"><a class="docs-heading-anchor" href="#Configuring-the-Base-Neural-Network">Configuring the Base Neural Network</a><a id="Configuring-the-Base-Neural-Network-1"></a><a class="docs-heading-anchor-permalink" href="#Configuring-the-Base-Neural-Network" title="Permalink"></a></h3><p>We&#39;ll create a neural network classifier with custom embedding dimensions for each categorical feature. Setting smaller embedding dimensions (like 2D) makes it easier to visualize the learned representations.</p><pre><code class="language-julia hljs"># Create the underlying supervised model that will learn the embeddings
base_clf = NeuralNetworkClassifier(
    builder = MLJFlux.Short(n_hidden = 14),
    optimiser = Optimisers.Adam(10e-2),
    batch_size = 20,
    epochs = 5,
    acceleration = CUDALibs(),
    embedding_dims = Dict(
        :Category =&gt; 2,
        :Type =&gt; 2,
        Symbol(&quot;Content Rating&quot;) =&gt; 2,
        :Genres =&gt; 2,
        Symbol(&quot;Android Ver&quot;) =&gt; 2,
    ),
    rng = 39,
);</code></pre><pre><code class="nohighlight hljs">â”Œ Info: The CUDA functionality is being called but
â”‚ `CUDA.jl` must be loaded to access it.
â”” Add `using CUDA` or `import CUDA` to your code.  Alternatively, configure a different GPU backend by calling `Flux.gpu_backend!`.
â”Œ Warning: `acceleration isa CUDALibs` but no CUDA device (GPU) currently live. Specifying an RNG seed when `acceleration isa CUDALibs()` may fail for layers depending on an RNG during training, such as `Dropout`. Consider using  `Random.default_rng()` instead. `
â”” @ MLJFlux ~/.julia/packages/MLJFlux/5eWpt/src/types.jl:62
</code></pre><h3 id="Creating-the-EntityEmbedder"><a class="docs-heading-anchor" href="#Creating-the-EntityEmbedder">Creating the EntityEmbedder</a><a id="Creating-the-EntityEmbedder-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-the-EntityEmbedder" title="Permalink"></a></h3><p>The <code>EntityEmbedder</code> wraps our neural network and can be used as a transformer in MLJ pipelines. By default, it uses <code>min(n_categories - 1, 10)</code> dimensions for any categorical feature not explicitly specified.</p><pre><code class="language-julia hljs"># Create the EntityEmbedder using the neural network
embedder = EntityEmbedder(base_clf)</code></pre><pre><code class="nohighlight hljs">EntityEmbedder(
  model = NeuralNetworkClassifier(
        builder = Short(n_hidden = 14, â€¦), 
        finaliser = NNlib.softmax, 
        optimiser = Adam(0.1, (0.9, 0.999), 1.0e-8), 
        loss = Flux.Losses.crossentropy, 
        epochs = 5, 
        batch_size = 20, 
        lambda = 0.0, 
        alpha = 0.0, 
        rng = 39, 
        optimiser_changes_trigger_retraining = false, 
        acceleration = ComputationalResources.CUDALibs{Nothing}(nothing), 
        embedding_dims = Dict{Symbol, Real}(:Category =&gt; 2, Symbol(&quot;Content Rating&quot;) =&gt; 2, Symbol(&quot;Android Ver&quot;) =&gt; 2, :Genres =&gt; 2, :Type =&gt; 2)))</code></pre><h2 id="Training-the-EntityEmbedder"><a class="docs-heading-anchor" href="#Training-the-EntityEmbedder">Training the EntityEmbedder</a><a id="Training-the-EntityEmbedder-1"></a><a class="docs-heading-anchor-permalink" href="#Training-the-EntityEmbedder" title="Permalink"></a></h2><p>Now we&#39;ll train the embedder on our training data. The model learns to predict app ratings while simultaneously learning meaningful embeddings for categorical features.</p><pre><code class="language-julia hljs"># Create and train the machine
mach = machine(embedder, X_train, y_train)
MLJ.fit!(mach, force = true, verbosity = 1);</code></pre><pre><code class="nohighlight hljs">[ Info: Training machine(EntityEmbedder(model = NeuralNetworkClassifier(builder = Short(n_hidden = 14, â€¦), â€¦)), â€¦).
â”Œ Info: The CUDA functionality is being called but
â”‚ `CUDA.jl` must be loaded to access it.
â”” Add `using CUDA` or `import CUDA` to your code.  Alternatively, configure a different GPU backend by calling `Flux.gpu_backend!`.
[ Info: MLJFlux: converting input data to Float32
Optimising neural net:  33%[========&gt;                ]  ETA: 0:00:00[KOptimising neural net:  50%[============&gt;            ]  ETA: 0:00:00[KOptimising neural net:  67%[================&gt;        ]  ETA: 0:00:00[KOptimising neural net:  83%[====================&gt;    ]  ETA: 0:00:00[KOptimising neural net: 100%[=========================] Time: 0:00:00[K
</code></pre><h3 id="Transforming-Data-with-Learned-Embeddings"><a class="docs-heading-anchor" href="#Transforming-Data-with-Learned-Embeddings">Transforming Data with Learned Embeddings</a><a id="Transforming-Data-with-Learned-Embeddings-1"></a><a class="docs-heading-anchor-permalink" href="#Transforming-Data-with-Learned-Embeddings" title="Permalink"></a></h3><p>After training, we can use the embedder as a transformer to convert categorical features into their learned embedding representations.</p><pre><code class="language-julia hljs"># Transform the data using the learned embeddings
X_train_embedded = MLJFlux.transform(mach, X_train)
X_test_embedded = MLJFlux.transform(mach, X_test);

# Check the schema transformation
println(&quot;Original schema:&quot;)
schema(X_train)
println(&quot;\nEmbedded schema:&quot;)
schema(X_train_embedded)</code></pre><pre><code class="nohighlight hljs">Original schema:

Embedded schema:
</code></pre><h2 id="Using-Embeddings-in-ML-Pipelines"><a class="docs-heading-anchor" href="#Using-Embeddings-in-ML-Pipelines">Using Embeddings in ML Pipelines</a><a id="Using-Embeddings-in-ML-Pipelines-1"></a><a class="docs-heading-anchor-permalink" href="#Using-Embeddings-in-ML-Pipelines" title="Permalink"></a></h2><p>One of the key advantages of entity embeddings is that they can be used as features in any downstream machine learning model. Let&#39;s create a pipeline that combines our <code>EntityEmbedder</code> with a k-nearest neighbors classifier.</p><pre><code class="language-julia hljs"># Load KNN classifier
KNNClassifier = @load KNNClassifier pkg = NearestNeighborModels

# Create a pipeline: EntityEmbedder -&gt; KNNClassifier
pipe = embedder |&gt; KNNClassifier(K = 5);

# Train the pipeline
pipe_mach = machine(pipe, X_train, y_train)
MLJ.fit!(pipe_mach, verbosity = 0)</code></pre><pre><code class="nohighlight hljs">trained Machine; does not cache data
  model: ProbabilisticPipeline(entity_embedder = EntityEmbedder(model = NeuralNetworkClassifier(builder = Short(n_hidden = 14, â€¦), â€¦)), â€¦)
  args: 
    1:	Source @225 â ScientificTypesBase.Table{Union{AbstractVector{ScientificTypesBase.Continuous}, AbstractVector{ScientificTypesBase.Multiclass{33}}, AbstractVector{ScientificTypesBase.Multiclass{2}}, AbstractVector{ScientificTypesBase.Multiclass{6}}, AbstractVector{ScientificTypesBase.Multiclass{48}}, AbstractVector{ScientificTypesBase.Multiclass{34}}}}
    2:	Source @148 â AbstractVector{ScientificTypesBase.Multiclass{10}}
</code></pre><h2 id="Visualizing-the-Learned-Embedding-Spaces"><a class="docs-heading-anchor" href="#Visualizing-the-Learned-Embedding-Spaces">Visualizing the Learned Embedding Spaces</a><a id="Visualizing-the-Learned-Embedding-Spaces-1"></a><a class="docs-heading-anchor-permalink" href="#Visualizing-the-Learned-Embedding-Spaces" title="Permalink"></a></h2><p>One of the most powerful aspects of entity embeddings is their interpretability. Since we used 2D embeddings, we can visualize how the model has organized different categories in the embedding space.</p><pre><code class="language-julia hljs"># Extract the learned embedding matrices from the fitted model
mapping_matrices = fitted_params(mach)[4]</code></pre><pre><code class="nohighlight hljs">Dict{Symbol, Matrix{Float32}} with 5 entries:
  :Category =&gt; [-0.334237 -0.0392749 0.104473 0.256099 -0.0655005 -0.141202 -0.0970246 0.179792 -0.270771 -0.214171 -0.12692 0.41105 0.256761 -0.0494666 -0.111133 0.285277 -0.331778 0.328676 -0.342993 -0.129262 -0.230373 -0.038213 0.108276 -0.153902 -0.324451 -0.237727 0.0345672 -0.0572035 -0.0585397 -0.288544 -0.242574 0.257894 0.00108838; 0.165236 -0.296432 -0.404019 -0.294493 0.185582 0.309341 -0.264846 -0.0410865 0.262034 0.384784 -0.0927044 0.0317509 0.232903 -0.406631 0.288323 0.0836039 0.334631 0.293926 0.290643 -0.334773 -0.306882 -0.00893126 0.185925 -0.309297 0.237027 0.0541817 0.39381 -0.400486 -0.123453 -0.163497 -0.00332076 0.0662401 0.160035]
  Symbol(&quot;Content Rating&quot;) =&gt; [0.133581 -0.728943 0.0488496 -0.17392 0.32843 0.563167; 0.525009 -0.258198 0.859755 -0.263517 -0.040722 0.33474]
  Symbol(&quot;Android Ver&quot;) =&gt; [0.170607 0.141154 -0.39162 0.403547 0.196919 -0.384571 -0.148519 -0.130053 0.170175 0.0752836 0.0634965 0.188923 0.179924 -0.346638 0.213056 0.104962 -0.0845368 -0.154221 -0.121818 -0.303438 0.275882 -0.201961 0.0978208 0.212295 -0.00877398 -0.296715 -0.0364835 -0.285863 -0.249095 0.00626427 -0.262972 0.152306 -0.131261 0.177531; -0.100683 -0.194721 0.364714 -0.199976 0.0840546 0.196454 -0.288194 0.215619 -0.282248 -0.0873126 -0.351141 0.0446604 0.37886 -0.151878 0.173701 -0.285421 -0.288342 0.270182 -0.181768 0.0513307 -0.0748576 0.303714 -0.230258 -0.123035 0.147936 0.169242 0.172273 -0.048809 -0.19322 0.239702 -0.130154 -0.407279 0.158713 0.322129]
  :Genres =&gt; [-0.146774 -0.310947 0.163455 0.186525 0.209192 -0.0957032 -0.309449 0.0804618 -0.289171 -0.105948 0.18964 -0.0232951 -0.303402 0.104239 0.213892 -0.0944015 -0.0128954 0.25166 -0.14625 0.340541 0.278481 0.118645 0.049088 -0.269987 -0.336882 -0.0115204 -0.121047 -0.269735 0.233099 -0.159103 -0.0351166 -0.102524 0.0211413 -0.0635436 -0.309698 -0.150375 -0.294988 0.243549 -0.121398 -0.257364 0.309162 0.260066 -0.32487 0.0512156 -0.113218 -0.128149 -0.285641 0.32328; -0.0240456 -0.0927238 -0.320587 -0.337704 0.265411 -0.102303 0.254456 0.288764 0.0950742 0.343972 -0.0132413 0.106584 0.0865783 -0.0157523 -0.121958 0.205434 -0.0508129 0.200128 -0.330792 0.337839 0.226497 0.131038 0.0368269 -0.243523 -0.259971 -0.144437 0.282105 0.223037 -0.0473506 0.131549 -0.22308 0.0791805 -0.17695 0.0639658 -0.344229 -0.274745 0.238469 0.0954359 0.340802 -0.0461901 -0.242701 0.016714 -0.0969492 0.142659 -0.0661325 0.165366 0.0977414 0.255571]
  :Type =&gt; [-1.02336 1.02435; -0.887775 0.944183]</code></pre><h3 id="Creating-Embedding-Visualization-Function"><a class="docs-heading-anchor" href="#Creating-Embedding-Visualization-Function">Creating Embedding Visualization Function</a><a id="Creating-Embedding-Visualization-Function-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-Embedding-Visualization-Function" title="Permalink"></a></h3><p>We&#39;ll create a helper function to plot the 2D embedding space for each categorical feature. Each point represents a category, and its position shows how the model learned to represent it.</p><pre><code class="language-julia hljs"># Function to create and display scatter plot for categorical embeddings
function plot_categorical_embeddings(feature_name, feature_categories, embedding_matrix)
    # Convert feature_name to string to handle both Symbol and String inputs
    feature_name_str = string(feature_name)

    # Create scatter plot for this feature&#39;s embeddings
    p = scatter(embedding_matrix[1, :], embedding_matrix[2, :],
        title = &quot;$(feature_name_str) Embeddings&quot;,
        xlabel = &quot;Dimension 1&quot;,
        ylabel = &quot;Dimension 2&quot;,
        label = &quot;$(feature_name_str)&quot;,
        legend = :topright,
        markersize = 8,
        size = (1200, 600))

    # Annotate each point with the actual category name
    for (i, col) in enumerate(eachcol(embedding_matrix))
        if i &lt;= length(feature_categories)
            cat_name = string(feature_categories[i])
            # Truncate long category names for readability
            display_name = length(cat_name) &gt; 10 ? cat_name[1:10] * &quot;...&quot; : cat_name
            annotate!(p, col[1] + 0.02, col[2] + 0.02, text(display_name, :black, 5))
        end
    end

    # Save the plot

    # Display the plot
    return p
end;</code></pre><h3 id="Generating-Embedding-Plots-for-Each-Categorical-Feature"><a class="docs-heading-anchor" href="#Generating-Embedding-Plots-for-Each-Categorical-Feature">Generating Embedding Plots for Each Categorical Feature</a><a id="Generating-Embedding-Plots-for-Each-Categorical-Feature-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-Embedding-Plots-for-Each-Categorical-Feature" title="Permalink"></a></h3><p>Let&#39;s visualize the embedding space for each of our categorical features to understand what patterns the model learned.</p><pre><code class="language-julia hljs"># Create separate plots for each categorical feature&#39;s embeddings

# Plot 1: Category embeddings
plot_categorical_embeddings(
    :Category,
    category_names[:Category],
    mapping_matrices[:Category],
);</code></pre><pre><code class="nohighlight hljs">Displayed embedding plot for: Category
</code></pre><p><img src="../embedding_category.png" alt="Category Embeddings"/> Notice that pairs such as social and entertainment, shopping and finance, and comics and art are closer together than others.</p><pre><code class="language-julia hljs"># Plot 2: Content Rating embeddings
plot_categorical_embeddings(
    Symbol(&quot;Content Rating&quot;),
    category_names[Symbol(&quot;Content Rating&quot;)],
    mapping_matrices[Symbol(&quot;Content Rating&quot;)],
);</code></pre><pre><code class="nohighlight hljs">Displayed embedding plot for: Content Rating
</code></pre><p><img src="../embedding_content_rating.png" alt="Content Rating Embeddings"/> The <code>Everyone</code> category is positioned far from all others.</p><pre><code class="language-julia hljs"># Plot 3: Genres embeddings
plot_categorical_embeddings(:Genres, category_names[:Genres], mapping_matrices[:Genres]);</code></pre><pre><code class="nohighlight hljs">Displayed embedding plot for: Genres
</code></pre><p><img src="../embedding_genres.png" alt="Genres Embeddings"/> Here the results may be less interpretable; the idea is that for purposes of indetifying the rating, the model considered categories closer together as more similar.</p><pre><code class="language-julia hljs"># Plot 4: Android Ver embeddings
plot_categorical_embeddings(
    Symbol(&quot;Android Ver&quot;),
    category_names[Symbol(&quot;Android Ver&quot;)],
    mapping_matrices[Symbol(&quot;Android Ver&quot;)],
);</code></pre><pre><code class="nohighlight hljs">Displayed embedding plot for: Android Ver
</code></pre><p><img src="../embedding_android_ver.png" alt="Android Ver Embeddings"/> Clear patterns like close proximity between (7.1 and up) and, 7.0-7.1</p><pre><code class="language-julia hljs"># Plot 5: Type embeddings (if it exists in the mapping)
plot_categorical_embeddings(:Type, sort(unique(df.Type)), mapping_matrices[:Type]);</code></pre><pre><code class="nohighlight hljs">Displayed embedding plot for: Type
</code></pre><p><img src="../embedding_type.png" alt="Type Embeddings"/> Indeed, <code>Free</code> and <code>Paid</code> are too dissimilar.</p><p>This demonstrates the power of entity embeddings as a modern approach to categorical feature encoding that goes beyond traditional methods like one-hot encoding or label encoding.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../wine_example/notebook/">Â« Wine Quality Prediction</a><a class="docs-footer-nextpage" href="../../../contributing/">Contributing Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.7.0 on <span class="colophon-date" title="Sunday 24 August 2025 03:29">Sunday 24 August 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
